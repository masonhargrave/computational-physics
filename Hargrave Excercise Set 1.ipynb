{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise Set 1\n",
    "\n",
    "## Excercise 1\n",
    "\n",
    "### Part a: Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World\n"
     ]
    }
   ],
   "source": [
    "print (\"Hello, World\") #prints \"Hello, World\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b: More Printing\n",
    "#### Section i: Print \"19 billion\" in scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9e+10\n"
     ]
    }
   ],
   "source": [
    "x=1.9E10              #store the number \"19 billion as x\n",
    "\n",
    "print (\"%3.1e\" % (x)) #prints x in scientific notation with 3 places (including .) and 1 digit after ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section ii: Print the value of the golden ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of the golden mean is 0.61803399\n"
     ]
    }
   ],
   "source": [
    "from numpy import *                                             #import numpy for sqrt function\n",
    "golden_mean = (sqrt(5) - 1)/2                                   #calculate the golden mean\n",
    "print (\"The value of the golden mean is %.8f\" % (golden_mean))  #print the golden mean as a float with 8 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S^{(up)} & = \\sum_{n=1}^{N} \\frac{1}{n} \\\\\n",
    "S^{(down)} & = \\sum_{n=N}^{1} \\frac{1}{n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## Part a: Calculate $S^{(up)}$ and $S^{(down)}$ in double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_up   = 16.695311365857272\n",
      "S_down = 16.695311365859965\n"
     ]
    }
   ],
   "source": [
    "N=10000000 #number of terms in sum\n",
    "S_up=0     #initial value of S_up\n",
    "S_down=0   #initial value of s_down\n",
    "\n",
    "#calculate the sum S_up\n",
    "for n in range(1, N+1):\n",
    "    S_up = S_up + 1/n\n",
    "\n",
    "print (\"S_up   = %.15f\" % (S_up)) #print S_up as a float with 15 decimal places\n",
    "\n",
    "#calculate the sum S_down\n",
    "for n in range(N,0,-1):\n",
    "    S_down = S_down + 1/n\n",
    "\n",
    "print (\"S_down = %.15f\" % (S_down)) #print S_down as a float with 15 decimal places\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b: Show that  $S^{(up)}$ and $S^{(down)}$ agree to high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The S_up is in 99.999999999999403 percent agreement with S_down\n",
      "\n",
      " Note that S_up is less than S_down\n"
     ]
    }
   ],
   "source": [
    "difference = S_up-S_down #calculate difference between S_up and S_down\n",
    "agree= (1-absolute(difference)/S_down)*100 #Calculate the percent agreement between S_up and S_down\n",
    "\n",
    "print (\"The S_up is in %.15f percent agreement with S_down\" % (agree)) #prints the percent agreement\n",
    "\n",
    "#prints a statement that tells you rather S_up or S_down is larger\n",
    "if (difference>0):\n",
    "    print (\"Note that S_up is greater than S_down\")\n",
    "if (difference<0):\n",
    "    print (\"\\n Note that S_up is less than S_down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c: Calculate $S^{(up)}$ and $S^{(down)}$ with double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N=100 we have: \n",
      " S_up   = 5.187378 \n",
      " S_down = 5.187377 \n",
      "\n",
      "For N=1000 we have: \n",
      " S_up   = 7.485478 \n",
      " S_down = 7.485472 \n",
      "\n",
      "For N=10000 we have: \n",
      " S_up   = 9.787613 \n",
      " S_down = 9.787604 \n",
      "\n",
      "For N=100000 we have: \n",
      " S_up   = 12.090851 \n",
      " S_down = 12.090152 \n",
      "\n",
      "For N=1000000 we have: \n",
      " S_up   = 14.357358 \n",
      " S_down = 14.392652 \n",
      "\n",
      "For N=10000000 we have: \n",
      " S_up   = 15.403683 \n",
      " S_down = 16.686031 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #import libraries\n",
    "\n",
    "#itterate for p = 2, ..., 7\n",
    "for p in range (2, 8):\n",
    "\n",
    "    N=10**p              #Set the number of terms in the sum to 10^p\n",
    "    S_up=np.float32(0)   #Set initial condition of S_up to be a 'single' 32-bit float\n",
    "    S_down=np.float32(0) #Set initial condition of S_down to be a 'single' 32-bit float\n",
    "\n",
    "    #Sum terms of 1/n for n=(1, ... ,N)\n",
    "    for n in range (1, N+1):\n",
    "        S_up = np.float32(S_up + 1/n)\n",
    "    \n",
    "    #Sum terms of 1/n fo n=(N, ... ,1)\n",
    "    for n in range (N,0,-1):\n",
    "        S_down = np.float32(S_down + 1/n)\n",
    "        \n",
    "    print (\"For N=%d we have: \\n S_up   = %.6f \\n S_down = %.6f \\n\" % (N,S_up,S_down)) #prints the number of  terms N and the  values of the sums S_up and S_down with 6 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d: Determine accuracy of floats by comparing to double values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N=100 we find: \n",
      " S_up   is in 99.999992 agreement with the true value of S\n",
      "\n",
      " S_down is in 99.999990 agreement with the true value of S\n",
      "\n",
      " S_up is more accurate than S_down \n",
      " \n",
      "\n",
      "For N=1000 we find: \n",
      " S_up   is in 99.999899 agreement with the true value of S\n",
      "\n",
      " S_down is in 99.999988 agreement with the true value of S\n",
      "\n",
      " S_up is less accurate than S_down \n",
      " \n",
      "\n",
      "For N=10000 we find: \n",
      " S_up   is in 99.999930 agreement with the true value of S\n",
      "\n",
      " S_down is in 99.999983 agreement with the true value of S\n",
      "\n",
      " S_up is less accurate than S_down \n",
      " \n",
      "\n",
      "For N=100000 we find: \n",
      " S_up   is in 99.994171 agreement with the true value of S\n",
      "\n",
      " S_down is in 99.999953 agreement with the true value of S\n",
      "\n",
      " S_up is less accurate than S_down \n",
      " \n",
      "\n",
      "For N=1000000 we find: \n",
      " S_up   is in 99.754260 agreement with the true value of S\n",
      "\n",
      " S_down is in 99.999478 agreement with the true value of S\n",
      "\n",
      " S_up is less accurate than S_down \n",
      " \n",
      "\n",
      "For N=10000000 we find: \n",
      " S_up   is in 92.263525 agreement with the true value of S\n",
      "\n",
      " S_down is in 99.944415 agreement with the true value of S\n",
      "\n",
      " S_up is less accurate than S_down \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #import packages\n",
    "\n",
    "#itterate for p = 2, ..., 7\n",
    "for p in range (2, 8):\n",
    "\n",
    "    N=10**p                #Set the number of terms in the sum to 10^p\n",
    "    S=0                    #Set initial value of S to be 0\n",
    "    S_up32=np.float32(0)   #Set initial condition of S_up32 to be a 'single' 32-bit float\n",
    "    S_down32=np.float32(0) #Set initial condition of S_down32 to be a 'single' 32-bit float\n",
    "\n",
    "    #Sum terms of 1/n for n=(1, ... ,N) in both 'double' 64-bit precision (in the case of S) and 'single' 32-bit precision (in the case of S_up)\n",
    "    for n in range (1, N+1):\n",
    "        S = S + 1 #Note that it doesn't matter rather the 64-bit value of S is calculated by the sum up or sum down method because the 64-bit values of S_up and S_down agree to the 6 decimal places of accuracy inherant to 32-bit 'single' floats.\n",
    "        S_up32 = np.float32(S_up32 + 1/n)\n",
    "    \n",
    "    #find and print the percent agreement between the 'true' 64-bit calculation of S and the 32 bit calculation of S_up\n",
    "    agree_up = (1-(absolute(S_up32-S)/S))*100\n",
    "    print (\"For N=%d we find: \\n S_up   is in %.6f agreement with the true value of S\" % (N,agree_up))\n",
    "    \n",
    "    #Sum terms of 1/n for n=(N, ..., 1) in 'single' 32-bit precision\n",
    "    for n in range (N,0,-1):\n",
    "        S_down32 = np.float32(S_down32 + 1/n)\n",
    "    \n",
    "    #find and print the percent agreement between the 'true' 64-bit calculation of S and the 32 bit calculation of S_down\n",
    "    agree_down = (1-(absolute(S_down32-S)/S))*100\n",
    "    print (\"\\n S_down is in %.6f agreement with the true value of S\" % (agree_down))\n",
    "    \n",
    "    #print a statement that tells you rather S_up or S_down are in better agreement with the 'true' value of S, and as such, is more accurate\n",
    "    if (agree_up > agree_down):\n",
    "        print (\"\\n S_up is more accurate than S_down \\n \\n\")\n",
    "    if (agree_up < agree_down):\n",
    "        print (\"\\n S_up is less accurate than S_down \\n \\n\")\n",
    "    if (agree_up == agree_down):\n",
    "        print (\"\\n S_up is just as acurate as  S_down \\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the percent agreement with the true value of S is decreasing as N increases.\n",
    "\n",
    "### Part e: Why is $S^{(up)}$ less accurate than $S^{(down)}$?\n",
    "\n",
    "To understand this phenomenon, note that the larger indexes of $n$ result in smaller values of $\\frac{1}{n}$. Thus it is clear that $S^{(up)}$ starts by summing large numbers and ends by summing small numbers where as $S^{(down)}$ starts by summing small numbers and ends by summing large numbers.\n",
    "\n",
    "Further, it is important to note that 32 bit floating point representations of numbers in a computer only have up to 6 decimal place accuracy (7 on a good day).\n",
    "\n",
    "This is where the $S^{(up)}$ approach loses it's edge. After the first few terms of the sum, we are left with a number of the form $1.abcdef$ where all 6 decimal places after the 1 are filled. Any terms with values smaller than $0.000001=1E-6$ will not have any effect on the total value of the sum.\n",
    "\n",
    "Here in lies the advantage of the $S^{(down)}$ approach. By summing the small numbers first, the 6 decimal places of accuracy can be used to store the small numbers. As these small numbers are summed, the total value of the sum increases in size and as such when the large numbers come around, the small numbers have been summed into a large number such that the addition of the large numbers does not cause as many significant decimal places of the total sum to be cut off. \n",
    "\n",
    "## Excercise 3\n",
    "\n",
    "### Part a: Determine the $n^{th}$ power of the golden mean $\\phi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nth power of the golden mean is 0.090169943749474 where n=5\n"
     ]
    }
   ],
   "source": [
    "from numpy import * #import numpy for sqrt function\n",
    "\n",
    "n=5                           #set the value of the power to which we will take the golden mean\n",
    "golden_mean = (sqrt(5) - 1)/2 #calculate the golden mean\n",
    "Nth_power = 1                 #sets the initial vale of phi^0 to 1\n",
    "\n",
    "#use the relation phi^n = phi^(n-1) * phi to calculate phi^n\n",
    "for i in range (1, n+1):\n",
    "    Nth_power = Nth_power*golden_mean\n",
    "\n",
    "print (\"The nth power of the golden mean is %.15f where n=%d\" % (Nth_power,n)) #print the value of phi^n as a float with 15 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b: Prove $ \\phi^{n+1} = \\phi^{n-1}-\\phi^{n}$\n",
    "\n",
    "Base Case:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& \\phi^{2} = 1 - \\phi \\\\\n",
    "\\implies & \\big( \\frac{\\sqrt{5}-1}{2} \\big)^2 = 1 - \\frac{\\sqrt{5}-1}{2} \\\\\n",
    "\\implies & \\frac{3-\\sqrt{5}}{2} = \\frac{3-\\sqrt{5}}{2} \\\\\n",
    "& \\textrm{TRUE}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Inductive Hypothesis:\n",
    "\n",
    "$ \\phi^{n+1} = \\phi^{n-1}-\\phi^{n} \\implies \\phi^{n+2} = \\phi^{n}-\\phi^{n+1}$\n",
    "\n",
    "Thus, by induction:\n",
    "\n",
    "$ \\phi^{n+1} = \\phi^{n-1}-\\phi^{n}$\n",
    "    \n",
    "QED\n",
    "\n",
    "### Part c: Implement a dynamic program using the claim from part b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of powers of the golden mean generated by the dynamic program with 64 bit floats: \n",
      "\n",
      "[ 1.00000000e+00  6.18033989e-01  3.81966011e-01  2.36067977e-01\n",
      "  1.45898034e-01  9.01699437e-02  5.57280900e-02  3.44418537e-02\n",
      "  2.12862363e-02  1.31556175e-02  8.13061876e-03  5.02499874e-03\n",
      "  3.10562002e-03  1.91937873e-03  1.18624129e-03  7.33137436e-04\n",
      "  4.53103854e-04  2.80033582e-04  1.73070272e-04  1.06963311e-04\n",
      "  6.61069610e-05  4.08563496e-05  2.52506114e-05  1.56057382e-05\n",
      "  9.64487316e-06  5.96086506e-06  3.68400810e-06  2.27685696e-06\n",
      "  1.40715113e-06  8.69705831e-07  5.37445302e-07  3.32260528e-07\n",
      "  2.05184774e-07  1.27075754e-07  7.81090197e-08  4.89667347e-08\n",
      "  2.91422850e-08  1.98244496e-08  9.31783539e-09  1.05066142e-08\n",
      " -1.18877885e-09  1.16953931e-08 -1.28841720e-08  2.45795650e-08\n",
      " -3.74637370e-08  6.20433021e-08 -9.95070391e-08  1.61550341e-07\n",
      " -2.61057380e-07  4.22607721e-07 -6.83665101e-07]\n",
      "\n",
      " \n",
      "\n",
      "Vector of powers of the golden mean generated by the dynamic program with 32 bit floats: \n",
      "\n",
      "[ 1.00000000e+00  6.18034005e-01  3.81966011e-01  2.36067977e-01\n",
      "  1.45898034e-01  9.01699437e-02  5.57280900e-02  3.44418537e-02\n",
      "  2.12862363e-02  1.31556175e-02  8.13061876e-03  5.02499874e-03\n",
      "  3.10562002e-03  1.91937873e-03  1.18624129e-03  7.33137436e-04\n",
      "  4.53103854e-04  2.80033582e-04  1.73070272e-04  1.06963311e-04\n",
      "  6.61069610e-05  4.08563496e-05  2.52506114e-05  1.56057382e-05\n",
      "  9.64487316e-06  5.96086506e-06  3.68400810e-06  2.27685696e-06\n",
      "  1.40715113e-06  8.69705831e-07  5.37445302e-07  3.32260528e-07\n",
      "  2.05184774e-07  1.27075754e-07  7.81090197e-08  4.89667347e-08\n",
      "  2.91422850e-08  1.98244496e-08  9.31783539e-09  1.05066142e-08\n",
      " -1.18877885e-09  1.16953931e-08 -1.28841720e-08  2.45795650e-08\n",
      " -3.74637370e-08  6.20433021e-08 -9.95070391e-08  1.61550341e-07\n",
      " -2.61057380e-07  4.22607721e-07 -6.83665101e-07]\n",
      "\n",
      " \n",
      "\n",
      "Vector of powers of the golden mean genearted by the method from pt a: \n",
      "\n",
      "[1.00000000e+00 6.18033989e-01 3.81966011e-01 2.36067977e-01\n",
      " 1.45898034e-01 9.01699437e-02 5.57280900e-02 3.44418537e-02\n",
      " 2.12862363e-02 1.31556175e-02 8.13061876e-03 5.02499874e-03\n",
      " 3.10562002e-03 1.91937873e-03 1.18624129e-03 7.33137436e-04\n",
      " 4.53103854e-04 2.80033582e-04 1.73070272e-04 1.06963310e-04\n",
      " 6.61069614e-05 4.08563490e-05 2.52506123e-05 1.56057367e-05\n",
      " 9.64487568e-06 5.96086099e-06 3.68401469e-06 2.27684629e-06\n",
      " 1.40716840e-06 8.69677897e-07 5.37490500e-07 3.32187398e-07\n",
      " 2.05303102e-07 1.26884295e-07 7.84188071e-08 4.84654881e-08\n",
      " 2.99533190e-08 1.85121692e-08 1.14411498e-08 7.07101942e-09\n",
      " 4.37013034e-09 2.70088908e-09 1.66924125e-09 1.03164783e-09\n",
      " 6.37593424e-10 3.94054407e-10 2.43539017e-10 1.50515390e-10\n",
      " 9.30236269e-11 5.74917632e-11 3.55318637e-11]\n",
      "\n",
      " \n",
      "\n",
      "Vector containing the percent difference between the powers calculated the 64 bit floats and the method from part a): \n",
      "\n",
      "[0.00000000e+00 0.00000000e+00 2.90660161e-14 2.35149010e-14\n",
      " 1.52191636e-13 2.46251240e-13 8.46691113e-13 1.97437573e-12\n",
      " 5.44387119e-12 1.39509790e-11 3.68467337e-11 9.61088829e-11\n",
      " 2.51987405e-10 6.59295318e-10 1.72652866e-09 4.51958046e-09\n",
      " 1.18329934e-08 3.09785620e-08 8.11035764e-08 2.12331246e-07\n",
      " 5.55891113e-07 1.45534112e-06 3.81013325e-06 9.97505759e-06\n",
      " 2.61150406e-05 6.83700631e-05 1.78995150e-04 4.68615385e-04\n",
      " 1.22685101e-03 3.21193763e-03 8.40896190e-03 2.20149481e-02\n",
      " 5.76358823e-02 1.50892699e-01 3.95042214e-01 1.03423394e+00\n",
      " 2.70765962e+00 7.08874491e+00 1.85585751e+01 4.85869804e+01\n",
      " 1.27202366e+02 3.33020118e+02 8.71857987e+02 2.28255384e+03\n",
      " 5.97580355e+03 1.56448568e+04 4.09587668e+04 1.07231444e+05\n",
      " 2.80735564e+05 7.34975249e+05 1.92419018e+06]\n",
      "\n",
      " \n",
      "\n",
      "Vector containing the percent difference between the powers calculated the 32 bit floats and the method from part a): \n",
      "\n",
      "[0.00000000e+00 2.65603599e-06 2.90660161e-14 2.35149010e-14\n",
      " 1.52191636e-13 2.46251240e-13 8.46691113e-13 1.97437573e-12\n",
      " 5.44387119e-12 1.39509790e-11 3.68467337e-11 9.61088829e-11\n",
      " 2.51987405e-10 6.59295318e-10 1.72652866e-09 4.51958046e-09\n",
      " 1.18329934e-08 3.09785620e-08 8.11035764e-08 2.12331246e-07\n",
      " 5.55891113e-07 1.45534112e-06 3.81013325e-06 9.97505759e-06\n",
      " 2.61150406e-05 6.83700631e-05 1.78995150e-04 4.68615385e-04\n",
      " 1.22685101e-03 3.21193763e-03 8.40896190e-03 2.20149481e-02\n",
      " 5.76358823e-02 1.50892699e-01 3.95042214e-01 1.03423394e+00\n",
      " 2.70765962e+00 7.08874491e+00 1.85585751e+01 4.85869804e+01\n",
      " 1.27202366e+02 3.33020118e+02 8.71857987e+02 2.28255384e+03\n",
      " 5.97580355e+03 1.56448568e+04 4.09587668e+04 1.07231444e+05\n",
      " 2.80735564e+05 7.34975249e+05 1.92419018e+06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Percent error on $\\\\phi^{n}$')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa8922fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n=50\n",
    "golden_mean = (sqrt(5) - 1)/2                                       #calculate the golden mean (psi)\n",
    "dynamic_golden_vector = [1, golden_mean]                            #generates array w/ initial conditions phi^0=1 and phi^1=phi\n",
    "dynamic_golden_vector_32 = [np.float32(1), np.float32(golden_mean)] #\"\" with 32 bit floats\n",
    "Nth_power = 1                                                       #Variable to keep track of the value of the Nth power of psi\n",
    "golden_vector = []                                                  #generates array used to store values of the Nth power of psi as in part a) \n",
    "golden_vector.append(Nth_power)                                     #adds initial condition phi^0=1 to golden_vector\n",
    "\n",
    "#calculates the value of psi^n using the relation found in part b) and stores in array for both 64 and 32 bit floats\n",
    "for i in range(2, n+1):\n",
    "    dynamic_golden_vector.append(dynamic_golden_vector[i-2] - dynamic_golden_vector[i-1])\n",
    "    dynamic_golden_vector_32.append(np.float(dynamic_golden_vector[i-2]) - np.float(dynamic_golden_vector[i-1]))\n",
    "\n",
    "#calculates the value of psi^n and stores in array using method from part a)\n",
    "for i in range(1, n+1):\n",
    "    Nth_power = Nth_power*golden_mean\n",
    "    golden_vector.append(Nth_power)\n",
    "\n",
    "#convert arrays to vectors\n",
    "dynamic_golden_vector = np.asarray(dynamic_golden_vector)\n",
    "dynamic_golden_vector_32 = np.asarray(dynamic_golden_vector_32)\n",
    "golden_vector = np.asarray(golden_vector)\n",
    "    \n",
    "#print vectors where the nth element of the  vector is the value of phi^n as generated by different methods above\n",
    "print (\"Vector of powers of the golden mean generated by the dynamic program with 64 bit floats: \\n\")\n",
    "print (dynamic_golden_vector)\n",
    "print (\"\\n \\n\")\n",
    "print (\"Vector of powers of the golden mean generated by the dynamic program with 32 bit floats: \\n\")\n",
    "print (dynamic_golden_vector_32)\n",
    "print (\"\\n \\n\")\n",
    "print (\"Vector of powers of the golden mean genearted by the method from pt a: \\n\")\n",
    "print (golden_vector)\n",
    "\n",
    "#creates vector where the nth element contains the percent difference between the 64-bit value of phi^n calculated via the recursion relation in part b) and the value of phi^n caclulated via the method from part a)\n",
    "difference_vector = absolute(dynamic_golden_vector-golden_vector)\n",
    "percent_difference_vector = (difference_vector / golden_vector)\n",
    "percent_difference_vector = percent_difference_vector*100\n",
    "\n",
    "#create vecotor [1, 2, ..., 50, 51]\n",
    "n_vector = np.arange(51)\n",
    "\n",
    "#prints the vector where the nth element contains the percent difference between the 64-bit value of phi^n calculated via the recursion relation in part b) and the value of phi^n caclulated via the method from part a)\n",
    "print (\"\\n \\n\")\n",
    "print (\"Vector containing the percent difference between the powers calculated the 64 bit floats and the method from part a): \\n\")\n",
    "print (percent_difference_vector)\n",
    "\n",
    "#creates vector where the nth element contains the percent difference between the 32-bit value of phi^n calculated via the recursion relation in part b) and the value of phi^n caclulated via the method from part a)\n",
    "difference_vector_32 = absolute(dynamic_golden_vector_32-golden_vector)\n",
    "percent_difference_vector_32 = (difference_vector_32 / golden_vector)\n",
    "percent_difference_vector_32 = percent_difference_vector_32*100\n",
    "n_vector = np.arange(51)\n",
    "\n",
    "#prints the vector where the nth element contains the percent difference between the 32-bit value of phi^n calculated via the recursion relation in part b) and the value of phi^n caclulated via the method from part a)\n",
    "print (\"\\n \\n\")\n",
    "print (\"Vector containing the percent difference between the powers calculated the 32 bit floats and the method from part a): \\n\")\n",
    "print (percent_difference_vector_32)\n",
    "\n",
    "#Note that we take the values for part a) to be 'true' values of phi^n and so the percent difference vectors calculated above tell us the percent error of the calculation phi^(power)\n",
    "\n",
    "#plots the error on phi^n vs the value of n for both 32-bit and 64-bit precision\n",
    "plt.figure(1)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(n_vector, percent_difference_vector, lw=2)\n",
    "plt.title('64 bit')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Percent error on $\\phi^{n}$')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(n_vector, percent_difference_vector_32, lw=2)\n",
    "plt.title('32 bit')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Percent error on $\\phi^{n}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! The recursion realtion is unstable because the error on $\\phi^{n}$ as compared to the phi calculated in part a) increases exponentially with $n$.\n",
    "\n",
    "It makes sense to use a) as the measuring stick with which to find the accuracy of the values found by method b) more than it makes sense to use b) as a measuring stick with which to find the accuracy of the values found by method a). A glance at the negative values of psi^n calculated by method b should convince you that this is true.\n",
    "\n",
    "### Part d\n",
    "\n",
    "Another value for which $\\phi^{n+1} = \\phi^{n-1} - \\phi^{n}$ is $\\bar{\\phi} = \\frac{\\sqrt{5}-1}{2}$.\n",
    "\n",
    "#### Motivation:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& \\phi^{n+1} = \\phi^{n-1} - \\phi^{n} \\textrm{(*)}\\\\\n",
    "\\implies & \\phi^{2} = 1 - \\phi \\\\\n",
    "\\implies & \\phi^{2} + \\phi - 1 = 0 \\\\\n",
    "\\implies & \\phi = \\frac{-1 \\pm \\sqrt{5}}{2} \\textrm{This is the general solution to equation (*)}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Because there are two values satisfying the recursion $\\phi^{n+1} = \\phi^{n-1} - \\phi^{n}$, imprecision in the computer causes the value of phi^{n+1} to be a linear combination of the value of $\\phi^{n+1}$ and $\\bar{\\phi}^{n+1}$. Over time, the value of coefficient for $\\bar{\\phi}^{n+1}$ is amplified, causing instability in our calculated value for $\\phi^{n+1}$.\n",
    "\n",
    "\n",
    "## Excercise 4:\n",
    "\n",
    "### Part a:\n",
    "\n",
    "#### Claim:\n",
    "\n",
    "$\n",
    "f''_{\\mathrm{mid}}(x) = \\frac{f(x+h) + f(x-h) - 2f(x)}{h^2}\n",
    "$\n",
    "\n",
    "Has an error of order $h^2$\n",
    "\n",
    "#### Proof:\n",
    "\n",
    "First, take the Taylor expansion of $f(x+h)$:\n",
    "\n",
    "$f(x+h) = f(x) + f'(x)h + f''(x)\\frac{h^2}{2!} + f'''(x)\\frac{h^3}{3!} + f^{(4)}\\frac{h^4}{4!} + \\ldots$\n",
    "\n",
    "Second, take the taylore expansion of $f(x-h)$:\n",
    "\n",
    "$f(x-h) = f(x) - f'(x)h + f''(x)\\frac{h^2}{2!} - f'''(x)\\frac{h^3}{3!} + f^{(4)}\\frac{h^4}{4!} - \\ldots $\n",
    "\n",
    "As such:\n",
    "$f(x+h) + f(x-h) = 2 \\cdot f(x) + f''(x) \\cdot h^2 + 2 \\cdot f^{(4)}\\frac{h^4}{4!} + \\ldots $\n",
    "\n",
    "This implies that:\n",
    "\n",
    "$\\frac{f(x+h) - 2 \\cdot f(x) + f(x-h)}{h^2} = f''(x) + 2 \\cdot \\frac{f^{(4)}(x)}{4!}h^2 + \\ldots$\n",
    "\n",
    "We can take the second term to be the error ($\\epsilon$) of $f''(x)$. Note that it is indeed proportional to $h^2$. We consider all following terms to be negligible:\n",
    "\n",
    "$\\epsilon = 2 \\cdot \\frac{f^{(4)}(x)}{4!}h^2 \\propto h^2$\n",
    "\n",
    "QED\n",
    "\n",
    "### Part b: Show that the above claim is true numerically\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error on the second derrivative of $\\\\sin(x)$ evalueated at $x=\\\\pi/2$')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFFCAYAAAD7KwoLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd8leX9//HXhwTC3kuBMGSPWDGCew9wMa1U259trbZa+7V2KCgo4ACsXVb7bWm1rdZWvzLjxL0XQTQJSyOiBNkjhJGQ8fn9cZ+0MYI5d8jJOUnez8cjD859znXnvI9EPrnu676uy9wdERGRaDWKdwAREalbVDhERCQUFQ4REQlFhUNEREJR4RARkVBUOEREJBQVDhERCUWFQ0REQomqcJjZQDM7y8xaVnp+VGxiiYhIoqqycJjZ/wCLgZ8AOWY2psLLd8UqmIiIJKbkKNpcBRzr7nvMrBcwz8x6ufvvAYtlOBERSTzRFI4kd98D4O7rzOx0guLRExUOEZEGJ5oxjk1m9o3yg0gRuRDoCAyLVTAREUlMVtXquGZ2KvCxu288yGsnufubsQonIiKJJ5rC8SdgJLAGeBZ41t031UI2ERFJQFUWjv80NBsIjAbOA9oALxMUkjfdvTRmCUVEJKGEKRwtywfJzawZcAZBITnB3dNjF1FERBJJmMLxMTAG+MjdSyLP9Xf3j2KYT0REEkyYwrEdyAIGAtuAVcBwd+8bu3giIpJoopnHUe5zdz8DwMy6A4OA/TFJJSIiCStM4WhjZicCK9w9D8iLUSYREUlgYS5VbQHeAIYAKQSXqnLc/ZexiyciIokmTI/jBHf/BMDMmgKDCYqIiIg0IFH3OEREREAbOYmISEgqHCIiEkqowmFmZ1b8U0REGp5QYxxm9r67Dy//M4a5REQkQVX3UpU2cBIRaaA0xiEiIqGocIiISCgqHCIiEkrYwrEn8mdBTQcREZG6QTPHRUQkFF2qEhGRUFQ4REQklKgLh5n9zsw0f0NEpIEL0+PYA2SYWQsAMzvXzN6MTSwREUlUYZccuQy4ASgC9gJ3uPvrMcomIiIJKMwOgGcBUwmWGzkCuNjd18Qwm4iIJKAwl6puAaa5++nAROAxrZIrItLwVHseh5kdAcx39xNrNpKIiCSyw5oAaGbN3H1/DeYREZEEp5njIiISiiYAiohIKGEmAM6J5jkREanfwvQ4zjnIc6NrKoiIiNQNyVU1MLNrgGuBPmaWVeGlVsBbsQomIiKJqcrBcTNrA7QDZgGTK7xU4O47YphNREQSUNglR9oB/YCm5c+5+2sxyCUiIgmqyktV5czsB8D1QHfgA+B44G1As8dFRBqQMIPj1wPHAZ+5+xnAMcDWmKQSEZGEFaZwFLp7IYCZpbj7amBAbGKJiEiiivpSFZBnZm2BRcDzZrYT+CI2sQ5Px44dvVevXvGOISJSpyxbtmybu3eqql21lhwxs9OANsCz7n6gGvliKj093TMzM+MdQ0SkTjGzZe6eXlW7MD2O/3D3V6tznoiI1H1aq0pEREJR4RARkVCiWXLkZ1/3urv/pubiiIhIootmjKNV5M8BBPM4MiLHFwGaNS4i0sBUeanK3We4+wygIzDc3X/u7j8HjiWYRR4VMxtlZmvMLNfMJh/k9RQzeyzy+rtm1ivyfGMz+4eZZZvZKjObEu17iohIzQszxpEKVLz19gDQK5oTzSwJuJ9gGfbBwLfMbHClZlcCO929L/BboHyvj0uAFHcfRlCsflheVEREJFBa5vz9zU956O11MX+vMLfjPgy8Z2YLAQfGAQ9Fee4IINfd1wKY2aPAGGBlhTZjgOmRx/OA+8zMIu/VwsySgWYEBWt3iNwiIvXax5sLuHF+Fss/30XTxo0YNbQrnVs1rfrEaoq6cLj7nWb2DHBK5KnvufvyKE/vBqyvcJwHjDxUG3cvMbN8oANBERkDbASaAzdoOXcREThQUsYfX8nl/pdzKS51OrdK4faxQ2NaNCDc6rhGcJmpjbvPNLNUMxvh7u9Fc/pBnqs8Zf1QbUYApcCRBPuCvG5mL5T3Xirkuxq4GiA1NTWKSCIiddf7n+9k8vwsPtq8B4BvjUhl8uiBtGnWOObvHeZS1R+BMoJl1GcCBcB8gjutqpIH9Khw3J2vrnNV3iYvclmqDbADuIxgaZNiYIuZvQmkA18qHO4+F5gLwZIjIT6XiEidsbeohHueW8Pf31qHO/Tq0JxZ49M44agOtZYhTOEY6e7DzWw5gLvvNLMmUZ67FOhnZr2BDcAkgoJQUQZwBcEeHxOBl9zdzexz4Ewz+yfBparjgd+FyC0iUi+8+tFWbl6QzYZd+0lqZFx1ah9+enY/mjZOqtUcYQpHceTuKAcws04EPZAqRcYsrgOWAEnAg+6+wsxmApnungE8ADxsZrkEPY1JkdPvB/4G5BBczvqbu2d95U1EROqpnXsPcPuTK1mwfAMAQ45szZwJaQzt1iYuecIUjnuBhUBnM7uToFcwLdqT3f1p4OlKz91a4XEhwa23lc/bc7DnRUTqO3fniayNzMhYwfa9B0hJbsRPz+7PVaf0JjkpfitGhbmr6hEzWwacRfCb/1h3XxWzZCIiDdgXu/YzbVEOL67eAsDxfdoza3wavTu2iHOycHdVzXH3m4DVB3lORERqQFmZ88i7nzHn2TXsKSqhVUoyN18wiEvTe9Co0cFuPq19YS5VnQNULhKjD/KciIhUQ+6WPUxZkMXSdTsBOHdwF24fO5QurWM7LyOsaFbHvQa4FuhjZhUHpVsBb8UqmIhIQ1FcWsafX/2Ee1/M5UBpGR1bpjBzzBBGD+1KMIUusUTT4/gX8AwwC6i4OGGBZnCLiByerLxd3Dgvi9WbCgD4Znp3bj5/EG2bRzvbofZVWTjcPR/IJ1iYsB3QD2gKYGa4u5ZWFxEJad+BEn77/Ec88ManlDmktm/OrPHDOKlvx3hHq1KYwfEfANcTzPr+gGAi3tsEM8lFRCRKb+ZuY/KCLNbv2E8jg6tO6c0N5/SneZMww87xEybl9QTLi7zj7meY2UBgRmxiiYjUP/n7irnjqZU8viwPgIFdWzFnQhpH92gb52ThhCkche5eaGaYWYq7rzazATFLJiJST7g7z+Rs4tbFK9i2p4gmSY34n7P68sPTjqJxHCfyVVeYwpFnZm2BRcDzZraTry5UKCIiFWzeXci0RTk8t3IzAMf1ases8Wn07dwyzsmqL8zM8XGRh9PN7GWC1WufjUkqEZE6rqzMeXTpemY9vYqCohJapiRz0+iBXD4iNWEm8lVXtUZi3P3Vmg4iIlJffLptL1MWZPHO2mDGwlkDO3P72KEc2bZZnJPVjLAbOV0O9CnfyAnoGuVGTiIi9V5JaRl/ef1TfvfCRxSVlNGhRRNuu3gIF6UdkZAT+aqrtjZyEhGp13I25HPT/CxWfLEbgPHDuzHtgsG0a5G4E/mqq7Y2chIRqZcKi0v53Qsf85fX11Ja5nRr24y7xg/jtP6d4h0tZmplIycRkfro7U+2M2VBFuu278MMvndSL35x7gBapNSNiXzVVZ2NnLpU2MhparQnm9ko4PcEOwD+1d1nV3o9BXgIOBbYDlzq7uvM7HLglxWapgHD3f2DENlFRGpM/v5iZj+zin+/tx6A/l1aMntCGsNT28U5We2o7kZOEGIjp0hP5X6CpdnzgKVmluHuKys0uxLY6e59zWwSMIegeDwCPBL5PsOAxSoaIhIvS1ZsYtqiHLYUFNE4yfjxGX259vS+NEmuexP5qivMXVW3VnrqksgihzOjOH0EkOvuayPf61FgDFCxcIwBpkcezwPuMzNzd6/Q5lvAv6PNLCJSU7YUFDI9YwVPZ28C4JjUtsyZkEb/Lq3inKz2hblUtbfC46bAhUC0W8d2A9ZXOM4DRh6qjbuXmFk+0AHYVqHNpQQFRkSkVrg7j2fmccdTK9ldWELzJknceN4AvnNCL5Lq+ES+6gpzqerXFY/N7B4gI8rTD/Zf18O0MbORwD53zznoG5hdDVwNkJqaGmUsEZFD+3z7PqYszOLN3O0AnNa/E3eOG0r3ds3jnCy+DmfovznQJ8q2eUCPCsfd+eo6V+Vt8swsmWBJk4obRU3iay5TuftcYC5Aenp65aIkIhK1ktIy/vbmOn79/BoKi8to17wxt140mLHf6FavJvJVV5gxjmz+2wNIAjoRTASMxlKgn5n1BjYQFIHLKrXJAK4g2ONjIvBS+fiGmTUCLgFOjTaviEh1rNq4m5vmZ5GVlw/AxUcfyW0XDaZDy5Q4J0scYXocF1Z4XAJsdveSaE6MjFlcBywhKDoPuvsKM5sJZLp7BvAA8LCZ5RL0NCZV+BanAnnlg+siIjWtsLiUP7z0MX9+dS0lZc6RbZpyx7ihnDmwS7yjJRz78k1L9UN6erpnZmbGO4aI1BHvfbqDyQuyWLs1uAfo/53QkxtHDaRlPZ/IV5mZLXP39KraVflfxcwK+OpANgSD2e7urauRT0Qk7goKi5nz7Gr++c7nABzVqQVzJqSR3qt9nJMltioLh7s3vJuURaTee3HVZqYuymFjfiHJjYxrTj+KH5/Rl6aNk+IdLeGF6oeZWTugH8E8DgDc/bWaDiUiEivb9hQx44mVPPFhcGPn0d3bMHtCGoOO0MWTaIW5q+oHwPUEt9J+ABxPcAfUmbGJJiJSc9ydhcs3MPPJlezaV0yzxkn8/Nz+fO+k3g12Il91helxXE+w98Y77n6GmQ0EZsQmlohIzVm/Yx+3LMrhtY+2AnBy347MGj+MHu0b9kS+6gpTOArdvdDMMLMUd19tZgNilkxE5DCVljn/eGsd9zy3hn0HSmnTrDFTLxjExGO7ayLfYQhTOPLMrC2wCHjezHby1dnfIiIJ4aPNBdw4L4sP1u8C4IJhRzD94iF0aqWJfIcrzFpV4yIPp5vZywRLgjwbk1QiItVUVFLKH1/+hD++kktxqdOldQq3jxnKuUO6xjtavRFmcPwG4HF3z3P3V2OYSUSkWpZ9tpPJ87P4eMseAC4bmcrk0QNp3bRxnJPVL2EuVbUGlpjZDuBRYJ67b45NLBGR6O0tKuFXS9bwj7fX4Q69O7Zg1vhhHN+nQ7yj1UthLlXNAGaYWRrBvhivmlmeu58ds3QiIlV4Zc0WblmYw4Zd+0lqZFx9Wh+uP6ufJvLFUHUWYtkCbCLYF7xzzcYREYnOjr0HuP3JlSxcvgGAod1aM3t8GkO7tYlzsvovzBjHNQQ9jU4EW7teVWnPcBGRmHN3Mj78ghlPrGTH3gOkJDfiZ+f058qTe5Oc1HD2/Y6nMD2OnsBP3f2DWIUREfk6X+zaz9RFOby0egsAJ/TpwKzxw+jVsUWckzUsYQrHzcBlZnaRu99uZqlAV3d/L0bZREQAKCtz/vnuZ8x5ZjV7D5TSqmkyt5w/iEuP66GJfHEQpnDcD5QRrE11O1AAzCdYhqRKZjYK+D3BRk5/dffZlV5PAR4CjiUYP7nU3ddFXksD/kxwZ1cZcJy7F4bILiJ1VO6WPUyen0XmZzsBOG9IF2aOGUqX1k2rOFNiJUzhGOnuw81sOYC77zSzJtGcaGZJBIXnHIK9xZeaWUalMZIrgZ3u3tfMJgFzgEsj+4//E/iOu39oZh2A4hC5RaQOOlBSxp9f/YQ/vJTLgdIyOrVKYebFQxg97Ih4R2vwwhSO4kgBKN8HvBPBb//RGAHklm/9amaPAmOAioVjDDA98ngecJ8FfdBzgSx3/xDA3beHyCwiddAH63cxeX4WqzcVAHBpeg9uPn8QbZprIl8iCFM47gUWAp3N7E5gIjA1ynO7AesrHOcBIw/VJrJHeT7QAegPuJktIbij61F3vztEbhGpI/YdKOHXz33E3978lDKH1PbNmT1+GCf27RjvaFJBmAmAj5jZMuAsgm1jx7r7qihPP9joVeXtaA/VJhk4mWAsZR/wYmRf3Be/dLLZ1cDVAKmpqVHGEpFE8cbH25iyMIv1O/bTyODqU/tww9n9adZEE/kSTagJgO6+GlhdjffJA3pUOO7OV1fWLW+TFxnXaAPsiDz/qrtvAzCzp4HhwJcKh7vPBeYCpKenH2yPdBFJQLv2HeCOp1Yxb1keAAO7tuLuiWmkdW8b52RyKNWZOV4dS4F+ZtYb2ABMAi6r1CYDuIJgV8GJwEvuXn6J6kYzaw4cAE4DfltLuUUkRtydp7M3cVtGDtv2HKBJciOuP6sfV5/ah8aayJfQaqVwRMYsrgOWENyO+6C7rzCzmUCmu2cADwAPm1kuQU9jUuTcnWb2G4Li48DT7v5UbeQWkdjYlF/ItMU5PL8yWCd1RK/2zJowjKM6tYxzMomGuYe7qmNmLQh2AyyNTaTDl56e7pmZmfGOISKVlJU5/176ObOfXk1BUQktU5KZPHogl41IpZH2/Y67yPhxelXtquxxmFkjgt/+LycYoC4CUsxsK/A0MNfdPz7MvCJSz63duocpC7J599MdAJw9qDO3jx3KEW2axTmZhBXNpaqXgReAKUCOu5cBmFl74AxgtpktdPd/xi6miNRVxaVl/OX1tfzuhY85UFJGx5ZNmH7xEC4YdoSWC6mjoikcZ7v7V2Zqu/sOgiVH5puZZuWIyFfkbMjnxnlZrNy4G4AJw7sz9YJBtGsR1aITkqCqLBzlRcPMfgfc4AcZFDlYYRGRhmv/gVJ+98JH/PWNTyktc7q3a8Zd44Zxav9O8Y4mNSDMXVV7gAwzm+Tue83sXOA2dz8pRtlEpA5665NtTFmQzWfb92EG3z+pNz8/tz8tUmrr7n+JtTAzx6ea2WXAK2ZWBOwFJscsmYjUKfn7i5n19CoeXRqsLjSgSytmTxjGMant4pxMalqYHQDPAq4iKBhHAFe6+5pYBRORuuPZnE3cujiHLQVFNElqxHVn9uVHpx1Fk2RN5KuPwvQdbwGmufsbZjYMeMzMfubuL8Uom4gkuC0Fhdy2eAXP5GwC4Nie7Zg9fhj9urSKczKJpTCXqs6s8DjbzEYT3FV1YiyCiUjicnf+L3M9dz61it2FJbRoksSNowbyneN7aiJfAxDNBEA7xJ1UGyOXrw7ZRkTqn8+272XKgmze+iTYGuf0AZ24c9wwurXVRL6GIqoJgGY2H1js7p+XPxnZ/e8EM7uCYJLg32MTUUQSQUlpGQ+++Sm/ef4jCovLaNe8MbddNIQx3zhSE/kamGgKxyjg+8C/I6vb7gKaAY2A54DfuvsHsYsoIvG24ot8Js/PJntDPgBjv3Ek0y4cTIeWKXFOJvEQzQTAQuCPwB8jM8Q7AvvdfVesw4lIfBUWl3Lvix/z59fWUlrmHNmmKXeOG8YZAzvHO5rEUZjbcVOACUAvILm8a+ruM2OSTETi6t2125myIJu12/ZiBlec0JNfjhpIS03ka/DC/AQsBvKBZQQr5IpIPVRQWMzsZ1bzyLvBkGbfzi2ZM2EYx/ZsH+dkkijCFI7u7j4qZklEJO5eWLmZqYty2LS7kORGxrWnH8WPz+xLSrL2/Zb/ClM43jKzYe6eXZ03MrNRwO8JdgD8q7vPrvR6CvAQcCywHbjU3deZWS9gFVA+S/0dd/9RdTKIyMFtLShi+hMreCprIwBH92jLnAnDGNi1dZyTSSIKUzhOBr5rZp8SXKoywN09raoTzSwJuB84B8gDlppZhruvrNDsSmCnu/c1s0nAHODSyGufuPs3QmQVkSi4O/Pf38AdT61k175imjVO4hfnDeC7J/YiSRP55BDCFI7Rh/E+I4Bcd18LYGaPAmOAioVjDDA98ngecJ/p5nCRmFm/Yx83L8zm9Y+3AXBKv47cNW4YPdo3j3MySXRhlhz57DDepxuwvsJxHjDyUG3cvcTM8oEOkdd6m9lyYDcw1d1fP4wsIg1aaZnz97fWcc+SNewvLqVt88ZMu2Aw44d300Q+iUo0S4684e4nm1kBUL6sSPlPl7t7NBdBD/bTWHmJkkO12Qikuvt2MzsWWGRmQ9x9d6WcVwNXA6SmpkYRSaThWbOpgJvmZ/HB+mAa1oVpR3DbRUPo1EoT+SR60UwAPDny5+Esd5kH9Khw3B344hBt8swsGWgD7IisgVUUybDMzD4B+gOZlXLOBeYCpKena90skQqKSkq5/+VP+N9Xcikudbq2bsrtY4dyzuAu8Y4mdVCYCYCXAM+6e4GZTQWGA7e7+/IoTl8K9IssWbIBmARcVqlNBnAF8DYwEXjJ3d3MOhEUkFIz6wP0A9ZGm1ukoVv22Q5ump9N7pY9AFw+MpWbRg+kddPGcU4mdVWYwfFp7v64mZ0MnAfcA/yJr45VfEVkzOI6YAnB7bgPuvsKM5sJZLp7BvAA8LCZ5QI7CIoLwKnATDMrAUqBH7n7jhC5RRqkPUUl/OrZ1Tz0zme4Q5+OLZg1fhgj+3So+mSRr2HRroZuZsvd/RgzmwVku/u/yp+LbcTw0tPTPTMzs+qGIvXUy2u2cMuCbL7ILySpkfGj0/rwkzP70bSxJvLJoZnZMndPr6pdmB7HBjP7M3A2MCcyYU/7QookkO17irj9yZUs+iAYQhzWrQ1zJqQx+EhN5JOaE6ZwfJNgifV73H2XmR0B/DI2sUQkDHdn8QdfMPPJlezYe4CmjRvxs3P68/2TepOcpN/vpGaFmcexD1hQ4Xgjwa2yIhJHG3btZ+rCbF5esxWAE4/qwKzxw+jZoUWck0l9pfWRReqosjLn4Xc+4+5nV7P3QCmtmiYz9YJBfDO9hybySUypcIjUQblbCrhpfjbLPtsJwOihXZlx8RA6t24a52TSEEQzc/xhd/+OmV3v7r+vjVAicnAHSsr406ufcN9LuRwoLaNTqxRuHzOUUUO7xjuaNCDR9DiONbOewPfN7CEqLQ2iORUitWP55zuZPD+bNZsLAJh0XA+mnD+INs00kU9qVzSF40/As0Afgt3/KhYOjzwvIjGy70AJ9yz5iL+99Snu0LNDc2aNH8aJR3WMdzRpoKJZq+pe4F4z+193v6YWMolIxGsfbeXmhdnk7dxPUiPjB6f25qdn9adZE03kk/gJczvuNWZ2NHBK5KnX3D0rNrFEGradew9wx1OrmP9+HgCDj2jN3RPTGNqtTZyTiYRb5PB/CJYtL5/L8YiZzXX3P8QkmUgD5O48mbWRGU+sYNueAzRJbsRPz+7HVaf0obEm8kmCCHM77g+Ake6+F8DM5hCsZKvCIVIDNubvZ9qiHF5YtQWAEb3bM3v8MPp0ahnnZCJfFqZwGMHqtOVKOfjmSyISQlmZ86/3Pmf2M6vZU1RCq5RkJp8/kG8dl0oj7fstCShM4fgb8K6ZLYwcjyVYCl1EqumTrXuYsiCb9z4N7mo/e1AX7hg7lK5tNJFPEleYwfHfmNkrwMkEPY3vRbmJk4hUUlxaxtzX1vL7Fz/mQEkZHVs2YcbFQzl/WFctFyIJL9SSI+7+PvB+dd7IzEYBvyfYyOmv7j670uspwEPAscB24FJ3X1fh9VRgJTDd3e+pTgaRRJCVt4ub5mezauNuACYe252pFwyibfMmcU4mEp1aWavKzJKA+4FzCPYWX2pmGe6+skKzK4Gd7t7XzCYBc4BLK7z+W+CZ2sgrEgv7D5Ty2xc+4q+vr6XMoXu7ZswaP4xT+nWKdzSRUGprkcMRQK67rwUws0eBMQQ9iHJjgOmRx/OA+8zMIvuOjyXYZ3xvLeUVqVFv5W5jysJsPtu+j0YGPzi5Nz87tz/Nm2idUal7wszjMOByoI+7z4xcOurq7u9FcXo3YH2F4zy+ulf5f9pE9ijPBzqY2X7gJoLeyi+izSuSCPL3FXPX06t4LDP48R/YtRWzJ6TxjR5t45xMpPrC/LrzR6AMOBOYCRQA84Hjojj3YKN9lTc7P1SbGcBv3X3P1w0amtnVBBMUSU1NjSKSSGw9k72RWzNWsLWgiCZJjfjJmX354WlH0SRZE/mkbgtTOEa6+3AzWw7g7jvNLNrRvDygR4Xj7sAXh2iTZ2bJQBtgB0HPZKKZ3Q20BcrMrNDd76t4srvPBeYCpKenVy5KIrVmy+5Cpi3OYcmKzQCk92zH7AnD6Nu5VZyTidSMMIWjODLI7QBm1omgBxKNpUA/M+sNbAAmAZdVapMBXEEwG30i8JK7O/9dGwszmw7sqVw0RBKBu/PY0vXc+fQqCgpLaNEkiZtGD+TbI3tqIp/UK2EKx73AQqCzmd1J8I/71GhOjIxZXAcsIbgd90F3X2FmM4FMd88gmEz4sJnlEvQ0JoXIJhJX67btZcqCbN5eux2AMwZ04o5xw+jWtlmck4nUPAt+qY+ysdlA4CyC8YgX3X1VrIIdjvT0dM/MzIx3DGkASkrLeOCNT/nN8x9RVFJG+xZNuO2iwVx89JGayCd1jpktc/f0qtqFuavqBuBxd7//sJKJ1BMrvsjnpvlZ5GwIJvKNO6Yb0y4cTPsWmsgn9VuYS1WtgSVmtgN4FJjn7ptjE0skcRUWl/L7Fz9m7mtrKS1zurVtxh3jhnLGgM7xjiZSK8KsVTUDmGFmaQQzul81szx3Pztm6UQSzLtrtzN5QTafbtuLGXz3xF784rwBtEzRRD5pOKrz074F2ESwnpR+xZIGYXdhMbOfWc2/3v0cgL6dWzJnQhrH9mwX52QitS/MGMc1BD2NTgRLglxVaa0pkXrpuRWbmLY4h827i2icZFx7el+uPeMoUpK177c0TGF6HD2Bn7r7B7EKI5JIthYUMT1jBU9lbwTgGz3aMmdCGgO6aiKfNGxhxjgmxzKISKJwd+Yty+OOp1aRv7+YZo2T+OV5A7jixF4kaSKfSNWFw8zecPeTzayAL68vZYC7e+uYpROpZet37OPmhdm8/vE2AE7p15G7xg2jR/vmcU4mkjiqLBzufnLkT/XPpd4qLXP+9uan/Pq5j9hfXErb5o259cLBjDummybyiVQSZnB8jrvfVNVzInXN6k27uWleFh/m5QNw0dFHcttFg+nYMiXOyUQSU5jB8XMI9sWoaPRBnhOpE4pKSrnvpVz+95VPKClzjmjTlDvGDuWsQV3iHU0koUUzxnENcC3Qx8yyKrzUCngrVsFEYilz3Q5ump/FJ1uDTSW/fXwqN40aSKumjeOcTCTxRdPj+BfBXt+zgIp3VhW4+45aTfmlAAAZW0lEQVSYpBKJkT1FJdz97Goefucz3KFPpxbMmZDGcb3axzuaSJ0RzeB4PpAPfMvM2gH9gKYAZoa7vxbbiCI146XVm7llYQ4b8wtJbmT86PSjuO7MvjRtrIl8ImGEGRz/AXA9we59HwDHE2y6dGZsoonUjO17ipj55EoWfxBsOpnWvQ2zx6cx+EjdSS5SHWEGx68n2F/8HXc/I7I3x4zYxBI5fO7Oog82MPOJlezcV0zTxo34+TkD+N5JvUhO0r7fItUVpnAUunuhmWFmKe6+2swGRHuymY0Cfk+wA+Bf3X12pddTgIeAYwkWULzU3deZ2Qgie4kTTDqc7u4LQ+SWBihv5z6mLsrhlTVbATipbwfuGjeMnh1axDmZSN0XpnDkmVlbYBHwvJntBL6I5sTIXuX3E9zSmwcsNbOMSoskXgnsdPe+ZjYJmEOwqGIOkB7ZfvYI4EMze8LdS0JklwaitMx5+O113L1kDfsOlNK6aTJTLxzMJcd210Q+kRoSZq2qcZGH083sZaAN8GyUp48Act19LYCZPQqMASoWjjHA9MjjecB9Zmbuvq9Cm6Z8edkTkf/4eHMBN83P4v3PdwFw/rCuTL94CJ1bNY1zMpH6pTpbx+a5+6sh36cbsL7CcR4w8lBtIr2LfKADsM3MRgIPEqzQ+x31NqSiAyVl/PGVXO5/OZfiUqdzqxRuHzuU84Z0jXc0kXqptraOPdg1gso9h0O2cfd3gSFmNgj4h5k94+6FXzrZ7GrgaoDU1NQoY0ld9/7nO5k8P4uPNu8B4FsjejB59CDaNNNEPpFYqa2tY/OAHhWOu/PV8ZHyNnlmlkxwKexLEwzdfZWZ7QWGApmVXptLZBA9PT1dl7Pqub1FJdzz3Br+/tY63KFXh+bMGp/GCUd1iHc0kXqvtraOXQr0M7PewAZgEnBZpTYZwBUEc0MmAi+5u0fOWR+5fNUTGACsq0ZuqSde/WgrNy/IZsOu/SQ1Mq46tQ8/PbufJvKJ1JJa2To28o/+dcASgttxH3T3FWY2E8h09wzgAeBhM8sl6GlMipx+MjDZzIqBMuBad98WbW6pP3buPcDtT65kwfINAAw5sjVzJqQxtFubOCcTaVjMPbqrOmY2G3i0Lmwdm56e7pmZmVU3lDrB3XkiayMzMlawfe8BUpIb8dOz+/ODU3rTWBP5RGqMmS1z9/Sq2mnrWEloG/P3M3VhDi+u3gLAyN7tmT0hjd4dNZFPJF60dawkpLIy55H3PmfOM6vZU1RCq5Rkbr5gEJem96CR9v0Wiauoto61YMrtEHf/vBYySQOXu2UPUxZksXTdTgDOHdyF28cOpUtrTeQTSQRRXaqK3N20kGAdKZGYKC4t48+vfsK9L+ZyoLSMji1TmDlmCKOHdtVyISIJJMztuO+Y2XHuvjRmaaTBysrbxY3zsli9qQCAS47tzi0XDKJt8yZxTiYilYUpHGcAPzSzz4C9/HeMIy0myaRB2H+glN88v4YH3viUMoce7Zsxa1waJ/frGO9oInIIURWOyBjHj4DPYhtHGpI3c7cxZUE2n+/YRyODq07pzQ3n9Kd5k+rMSxWR2hJmjOO37q4xDjls+fuKueOplTy+LA+AgV1bMWdCGkf3aBvnZCISDY1xSK1xd57J2cSti1ewbU8RTZIa8T9n9eWHpx2liXwidUjYMY4fmdk6NMYhIW3eXci0RTk8tzJYUPm4Xu2YNT6Nvp1bxjmZiIQVpnCMjlkKqbfKypzHMtdz19OrKCgsoWVKMjeNHsjlI1I1kU+kjgpTOD4HLgf6uPtMM0sFuqIBczmEddv2MnlBFu+sDVbHP2tgZ24fO5Qj2zaLczIRORxhCscfCVanPROYCRQA84HjYpBL6rCS0jL+8vqn/O6FjygqKaNDiybcdvEQLko7QhP5ROqBMIVjpLsPN7PlAO6+08w0O0u+JGdDPjfNz2LFF7sBGH9MN6ZdOJh2LfSjIlJfhCkcxWaWRGShQzPrRNADEaGwuJTfvfAxf3l9LaVlTre2zbhz3FBOHxDtXl8iUleEuQfyXmAh0MXM7gTeAO6K9mQzG2Vma8ws18y+skS7maWY2WOR1981s16R588xs2Vmlh3588wQmaUWvLN2O6N//zp/evUTytz53km9eO6GU1U0ROqpMPtxPGJmy4CzIk+NdfdV0Zwb6ancD5xDsLf4UjPLqLSD4JXATnfva2aTgDkEOw5uAy5y9y/MbCjBLoLdos0tsbO7sJhZT6/m3+8Fiyb379KS2RPSGJ7aLs7JRCSWotmP42eHeGm0mY12999E8T4jgFx3Xxv5no8CY4CKhWMMMD3yeB5wn5mZuy+v0GYF0NTMUty9KIr3lRh5Zc0WpizIZmN+IY2TjB+f0ZdrT+9Lk2RN5BOp76LpcbSK/DmA4A6qjMjxRcBrUb5PN2B9heM8YOSh2kT2KM8HOhD0OMpNAJaraMRP/v5i7nxqJf+XGSwXcnSPtvxqYhr9u7Sq4kwRqS+i2chpBoCZPQcMd/eCyPF04PEo3+dg92BW3uz8a9uY2RCCy1fnHvQNzK4GrgZITU2NMpaE8fLqoJexaXchTZIb8bNz+vODk3uTrOVCRBqUMHdVpQIHKhwfAHpFeW4e0KPCcXfgi0O0yTOzZKANsAPAzLoTDMz/P3f/5GBv4O5zgbkA6enplYuSHIb8/cXc/uRK5kUWJfxGj7bcc0kafTurlyHSEIUpHA8D70V2AnRgHPCPKM9dCvQzs97ABmAScFmlNhnAFcDbwETgpciqvG2Bp4Ap7v5miLxSA15avZkpC7LZvLuIJsmN+MW5/bny5D4kabkQkQYrzF1Vd5rZM8Apkae+V2ng+uvOLTGz6wjuiEoCHnT3FWY2E8h09wzgAeBhM8sl6GlMipx+HdAXmGZm0yLPnevuW6LNLuHl7ytm5pMrmf9+0MsYntqWuycerUUJRQRzr39XddLT0z0zMzPeMeqsF1Zu5uaF2WwpKCIluRG/OHcA3z+5t3oZIvWcmS1z9/Sq2mmrNfmPXfsOMPOJlSxYvgGAY3u24+6JaRzVSb0MEfkvFQ4B4PlIL2NrpJfxy/MG8L2T1MsQka9S4Wjgdu07wPSMFSz6ILjJLb1nO351ydH07tgizslEJFEdzsxxAKKcOS4JaMmKTdyyMIdte4po2rgRN543kCtO7KVehoh8rdqaOS4JZOfeA9yWsYKMD4NexnG92nH3RPUyRCQ6tTVzXBLEszmbmLoom217DtCscRI3jhrAFSf00jauIhK12po5LnG2I9LLeCLSyxjRuz2/mphGzw7qZYhIONWdOQ4wFnio5iNJTXsmeyPTFuf8p5cxefRAvnN8T/UyRKRaqjtz3Akxc1ziY/ueIm7NWMFTWRsBOL5Pe+6ecDSpHZrHOZmI1GVRFw4zSwEGAi0i511kZhe5+8xYhZPqezp7I9MW5bB97wGaN0liyuiBXD5SvQwROXxhLlUtBvKBZYD2w0hQ2/YUcdviFTyVHfQyTujTgbsnptGjvXoZIlIzwhSO7u4+KmZJ5LC4O09lb+TWxSvYUd7LOH8Ql49IVS9DRGpUmMLxlpkNc/fsmKWRatlaUMSti3N4JmcTACce1YE5E9TLEJHYCFM4Tga+a2afElyqMsDdPS0myaRK7s4TWRu5bXEOO/cV06JJEjdfMIjLRqRipl6GiMRGmMIxOmYpJLStBUVMW5TDsyuCXsbJfTsye8IwurdTL0NEYivM7bifmdnR/Hcjp9fd/cPYxJJDcXcyPvyC2zJWsGtfMS1TkrnlgkFMOq6HehkiUisaRdvQzK4HHgE6R77+aWY/CXH+KDNbY2a5Zjb5IK+nmNljkdffNbNekec7mNnLZrbHzO6L9v3qoy0Fhfzw4WVc/+gH7NpXzCn9OrLkhlP5li5NiUgtCnOp6kpgpLvvBTCzOQT7g/+hqhPNLAm4HzgHyAOWmlmGu6+s9P13untfM5sEzAEuBQqBacDQyFeD4+4s/iDoZeTvL6ZVSjJTLxzEN9PVyxCR2hemcBhQWuG4NPJcNEYAue6+FsDMHgXGABULxxhgeuTxPOA+M7NIoXrDzPqGyFpvbNldyM0Lc3hh1WYATu3fidnjh3Fk22ZxTiYiDVWYwvE34N1Ka1U9EOW53YD1FY7zgJGHauPuJWaWD3QAtoXIWG+4OwuXb2DGEyv/08uYduFgLknvrl6GiMRVmMHx35jZKwS35Rrh1qo62L90Xo02h34Ds6uBqwFSU1OjPS0hbd5dyM0Lsnlx9RYATh/QiVnjh3FEG/UyRCT+Qm0d6+7vA+9X433ygB4VjrsDXxyiTZ6ZJQNtgB0hss0F5gKkp6dHXXASibuz4P0NzHhiBbsLS2jVNJlbLxzMxGPVyxCRxBHmrqp/mFnbCsftzOzBKE9fCvQzs95m1gSYxH93EiyXAVwReTwReMnd62QBqI5N+YVc+Y9Mfv74h+wuLOGMAZ14/obTuEQD4CKSYML0ONLcfVf5gbvvNLNjojkxMmZxHbAESAIedPcVZjYTyHT3DILxkofNLJegpzGp/HwzWwe0BpqY2Vjg3Ep3ZNVZ7s68ZXnMfHIlBYUltG6azG0XDWH88G4qGCKSkMIUjkZm1s7ddwKYWfsw57v708DTlZ67tcLjQuCSQ5zbK0TOOmNj/n6mLMjmlTVbAThrYGfuGj+MLq2bxjmZiMihhSkcvwbeNrPHCQatvwncGZNU9Zy783hmHrc/uZKCoqCXMf3iIYw7Rr0MEUl8YXoMD5lZJnAmwR1Q4+vL5aLa9MWuoJfx6kdBL+PsQZ25a9wwOquXISJ1RJgdAA0YDrR395lmlmpmI9z9vdjFqz/cnf/LXM8dT66ioKiENs0aM+PiIYz5xpHqZYhInRLmUtUfgTKCHsdMoACYDxwXg1z1yoZd+5k8P4vXPw7mMp4zuAt3jhtK51bqZYhI3ROmcIx09+Fmthz+c1dVkxjlqhfcnUeXrufOp1axp6iEts2DXsbFR6uXISJ1V5jCURxZrNABzKwTQQ9EDqJyL+PcwV24Q70MEakHwhSOe4GFQGczu5Ngkt7UmKSqwyr3Mto1b8yMMUO5KO0I9TJEpF4Ic1fVI2a2DDgr8tQYd18dm1h10xe79jN5QTavRe6YGjWkK7ePHUqnVilxTiYiUnPCLDlyCbDB3e8H2gN3mdnwmCWrQ9ydx5Z+znm/fY3XPtpK2+aNufdbx/C/3x6uoiEi9U6YS1XT3P1xMzuZYEOmXwP/y1eXR29QNubvZ/L8/87L0B1TIlLfhSkc5Zs4XQD8yd0Xm9n0mo9UN1ReY0rzMkSkoQhTODaY2Z+Bs4E5ZpZCiEtd9cnm3YVMWZDNS5H9MjT7W0QakjCF45vAKOAed99lZkcAv4xNrMRUvivf9IxgvwytMSUiDVGYu6r2AQsqHG8ENsYiVCIK9v7O5oVVQS/jzIGdmaWVbEWkAQq1A2BD5O4s/uALbstYEez9rV35RKSBq7UxCjMbZWZrzCzXzCYf5PUUM3ss8vq7ZtarwmtTIs+vMbPzaivzloJCfvjwMn762Afk7y/mtP6deO6GU7Urn4g0aLXS44gsVXI/wW28ecBSM8uotCz7lcBOd+9rZpOAOcClZjaYYDfAIcCRwAtm1t/dS4kRdyfjw6CXsWtfMa1Skpl24WAuSVcvQ0Qk7LLqlwN9ypdVB7pGuaz6CCDX3ddGvtejwBigYuEYA0yPPJ4H3Bd5zzHAo+5eBHwa2Vp2BPB2tNnD2LaniGmLcngmZxMAp/TryJwJaRzZtlks3k5EpM6prWXVuwHrKxzn8dWJg/9pE9mjPB/oEHn+nUrndguRO2r/l7meWxfnUFhcRosmSUy9cDCTjtNlKRGRimprWfWD/cvrUbaJ5lzM7GrgaoDU1NQoY33Zzr0HKCwu48SjOjBnQho92jev1vcREanPamtZ9TygR4Xj7sAXh2iTZ2bJQBtgR5Tn4u5zgbkA6enpXyks0Zh4bHfOHdKVXh2aq5chInIIYe6qKl9WvUtkWfU3gLuiPHcp0M/Mekd6KZOAjEptMoArIo8nAi+5u0eenxS566o30A+IyXa1HVqm0LtjCxUNEZGvcTjLqo9191VRnltiZtcBS4Ak4EF3X2FmM4FMd88AHgAejgx+7yAoLkTa/R/BQHoJ8ONY3lElIiJfz4Jf6qNoGKxNNQHoRYWC4+4zY5LsMKSnp3tmZma8Y4iI1Clmtszd06tqF2aMYzGQDywDiqobTERE6rYwhaO7u4+KWRIREakTwgyOv2Vmw2KWRERE6oQqexxmlk1wC24y8D0zW0twqcoAd/e02EYUEZFEEs2lqgtjnkJEROqMMHdVzXH3m6p6LhGY2Vbgs8P4Fh2BbTUUpy5oaJ8X9JkbCn3mcHq6e6eqGoUpHO+7+/BKz2XVx0tVZpYZzS1p9UVD+7ygz9xQ6DPHRjRjHNcA1wJ9zCyrwkutgDdjFUxERBJTNGMc/wKeAWYBFTdgKnD3HTFJJSIiCavKwuHu+QQT/74V+zgJY268A9SyhvZ5QZ+5odBnjoGoxzhERESgFvccFxGR+iHqwhFZ1vwyM7vZzG4t/4pluFgys1FmtsbMcs1s8kFeTzGzxyKvv2tmvWo/Zc2K4jP/zMxWmlmWmb1oZj3jkbMmVfWZK7SbaGZuZnX+DpxoPrOZfTPyd73CzP5V2xlrWhQ/26lm9rKZLY/8fJ8fj5w1xcweNLMtZpZziNfNzO6N/PfIMrPhB2tXbe4e1RfwLPAYcCPw8/KvaM9PpC+Cpd0/AfoATYAPgcGV2lwL/CnyeBLwWLxz18JnPgNoHnl8TUP4zJF2rYDXCLYoTo937lr4e+4HLAfaRY47xzt3LXzmucA1kceDgXXxzn2Yn/lUYDiQc4jXzye4qcmA44F3a/L9G+oihyOAXHdfC2BmjwJjCPb8KDcGmB55PA+4z8zMI38rdVCVn9ndX67Q/h3g27WasOZF8/cMcDtwN/CL2o0XE9F85quA+919J4C7b6n1lDUrms/sQOvI4zYcZBfRusTdX6viKsgY4KHIv1fvmFlbMzvC3TfWxPs31EUOuwHrKxznRZ47aBt3LyG4s6xDraSLjWg+c0VXEvzGUpdV+ZnN7Bigh7s/WZvBYiiav+f+QH8ze9PM3jGzuv4LYTSfeTrwbTPLA54GflI70eIm7P/voYTpcZwMfNfMPqXuL3J4sL1hK/ckomlTl0T9eczs20A6cFpME8Xe135mM2sE/Bb4bm0FqgXR/D0nE1yuOh3oDrxuZkPdfVeMs8VKNJ/5W8Df3f3XZnYCwW6jQ929LPbx4iKm/36FKRyja+pNE0Ae0KPCcXe+2nUtb5NnZskE3du6POExms+MmZ0N3AKc5u51fcOuqj5zK2Ao8Epkn/muQIaZXezudXULyWh/tt9x92LgUzNbQ1BIltZOxBoXzWe+EhgF4O5vm1lTgjWd6vplukOJ6v/36or6UpW7f3awr5oKUsuWAv3MrLeZNSEY/M6o1CYDuCLyeCLwUh0e34AoPnPkss2fgYvrwXVvqOIzu3u+u3d0917u3otgXKcuFw2I7md7EcGNEJhZR4JLV2trNWXNiuYzfw6cBWBmg4CmwNZaTVm7MoD/F7m76nggv6bGNyBcjwMzOxo4JXL4urt/WFNBapO7l5jZdcASgjsyHnT3FWY2E8h09wzgAYLubC5BT2NS/BIfvig/86+AlsDjkd/AP3f3i+MW+jBF+ZnrlSg/8xLgXDNbCZQCv3T37fFLfXii/Mw/B/5iZjcQXLL5bl3+RdDM/k1wqbFjZNzmNqAxgLv/iWAc53wgF9gHfK9G3z/a/3Zmdj3B3RgLIk+NA+a6+x9qMpCIiCS2MIUjCzjB3fdGjlsAb9fRwXEREammMLfjGkG3tlwpBx+5FxGReizMGMffgHfNbGHkeCzBOICIiDQgoVbHjax3cjJBT+M1d18eq2AiIpKYtKy6iIiEomXVRUQklKgKR2QSSY+qW4qISH0XVeGITJRZFOMsIg2GmY01s7+Y2WIzOzfeeUTCCHOp6h0zOy5mSUTqITM728wervy8uy9y96sIFli8tNaDiRyGMLfjngH80Mw+A/ZSt1fHFaktRxNsmnQoU4H7aymLSI1oqKvjitSWo4FNZvY6wQq033b3FyxYDGw28Iy7vx/XhCIhhVodF2gLXBT5aluHV8cVqS1HA9vc/RSC7Ygvjzz/E+BsYKKZ/She4USqQ4scisSImTUmWK68p7uXmdk3CdZ7uyHO0UQOS5hLVVcCIysscjgHeBtQ4RA5uMHAhxV2mUsDcuKYR6RGaJFDkdg5Gqi4Z00akBWnLCI1RoscisTO0cB7FY6Hoh6H1ANRjXFE7gDpDnRCixyKiDRoYQbHl7n7sTHOIyIiCU4zx0VEJJQwPY6VQH9AM8dFRBqwMGMcpxAUjS/RJEARkYZFYxwiIhKKxjhERCSUsGMcA4B1aIxDRKTBClM4eh7seY1xiIg0LFVeqjKzG+E/BWKEu39W/gX8MNYBRUQksUQzxjGpwuMplV4bVYNZRESkDoimcNghHh/sWERE6rloCocf4vHBjkVEpJ6rcnDczEr5711UzYB95S8BTd29cUwTiohIQon6rioREREINwFQREREhUNERMJR4RARkVBUOEREJBQVDhERCUWFQ0REQlHhEBGRUP4/tY6ST3TfKkMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa8786aeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = 1       #Set initial value of h\n",
    "x = np.pi/2 #Set initial value of x\n",
    "\n",
    "#create empty vector\n",
    "h_squared_vector=[]\n",
    "error_vector=[]\n",
    "\n",
    "while h>0.0000001:                                                          #Set some tolerance on how small h can get (to avoid bumping into round-off error)\n",
    "    second_derivative_of_sin = (np.sin(x+h)+np.sin(x-h)-2*np.sin(x))/(h**2) #Evaluate the second derivative of sin(x) at pi/2 by the midpoint approximation\n",
    "    error=(1+second_derivative_of_sin)                                      #Calculate the difference between the approximated value of the second derivative of sin(x) evaluated at pi/2 and its true analytical value of -1                              \n",
    "    error_vector.append(error)                                              #Fill the error vector such that the nth element of the error vector contains the absoulute error of the approximated value of the second derivative of sin(x) evaluated at pi/2 when h=1/2^n\n",
    "    h_squared_vector.append(h**2)                                           #Fill h squared vector such that the nth element of the h squared vector contains the value of h^2=(1/2^n)^2\n",
    "    h=h/2                                                                   #Sets the value of h for the next cycle to be half of the value for this cycle\n",
    "\n",
    "#convert arrays to vectors\n",
    "h_squared_vector = np.asarray(h_squared_vector)\n",
    "error_vector = np.asarray(error_vector)\n",
    "\n",
    "#plot the value of the error on second derrivative of sin(x) evaluated at pi/2 against h^2\n",
    "plt.plot(h_squared_vector, error_vector, lw=2)\n",
    "plt.xlabel('$h^2$')\n",
    "plt.ylabel('Error on the second derrivative of $\\sin(x)$ evalueated at $x=\\pi/2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, by the plot above, Error scales with $h^2$ just as predicted analytically. Note that there is no noticible interference caused by the extra terms in the taylor expansion we ignored.\n",
    "\n",
    "## Excercise 5:\n",
    "\n",
    "### Compute the spherical Bessel functions j_l(x) for x = 0.1, x = 1, and x = 10 and for l = 0, 1, ..., 25\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "j_{l+1}(x) = \\frac{2l+1}{x} \\cdot j_l - j_{l+1}(x)\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For x = 0.1 we have the following set of bessel functions: \n",
      "\n",
      "When l = 0, j_l = 9.983342e-01 \n",
      "\n",
      "When l = 1, j_l = 3.330001e-02 \n",
      "\n",
      "When l = 2, j_l = 6.661906e-04 \n",
      "\n",
      "When l = 3, j_l = 9.518520e-06 \n",
      "\n",
      "When l = 4, j_l = 1.057720e-07 \n",
      "\n",
      "When l = 5, j_l = 9.616310e-10 \n",
      "\n",
      "When l = 6, j_l = 7.397541e-12 \n",
      "\n",
      "When l = 7, j_l = 4.931887e-14 \n",
      "\n",
      "When l = 8, j_l = 2.901200e-16 \n",
      "\n",
      "When l = 9, j_l = 1.526986e-18 \n",
      "\n",
      "When l = 10, j_l = 7.271511e-21 \n",
      "\n",
      "When l = 11, j_l = 3.161582e-23 \n",
      "\n",
      "When l = 12, j_l = 1.264651e-25 \n",
      "\n",
      "When l = 13, j_l = 4.683954e-28 \n",
      "\n",
      "When l = 14, j_l = 1.615174e-30 \n",
      "\n",
      "When l = 15, j_l = 5.210291e-33 \n",
      "\n",
      "When l = 16, j_l = 1.578890e-35 \n",
      "\n",
      "When l = 17, j_l = 4.511148e-38 \n",
      "\n",
      "When l = 18, j_l = 1.219238e-40 \n",
      "\n",
      "When l = 19, j_l = 3.126270e-43 \n",
      "\n",
      "When l = 20, j_l = 7.625092e-46 \n",
      "\n",
      "When l = 21, j_l = 1.773286e-48 \n",
      "\n",
      "When l = 22, j_l = 3.940655e-51 \n",
      "\n",
      "When l = 23, j_l = 8.384409e-54 \n",
      "\n",
      "When l = 24, j_l = 1.711111e-56 \n",
      "\n",
      "When l = 25, j_l = 3.355132e-59 \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "For x = 1.0 we have the following set of bessel functions: \n",
      "\n",
      "When l = 0, j_l = 8.414710e-01 \n",
      "\n",
      "When l = 1, j_l = 3.011687e-01 \n",
      "\n",
      "When l = 2, j_l = 6.203505e-02 \n",
      "\n",
      "When l = 3, j_l = 9.006581e-03 \n",
      "\n",
      "When l = 4, j_l = 1.011016e-03 \n",
      "\n",
      "When l = 5, j_l = 9.256116e-05 \n",
      "\n",
      "When l = 6, j_l = 7.156936e-06 \n",
      "\n",
      "When l = 7, j_l = 4.790134e-07 \n",
      "\n",
      "When l = 8, j_l = 2.826499e-08 \n",
      "\n",
      "When l = 9, j_l = 1.491377e-09 \n",
      "\n",
      "When l = 10, j_l = 7.116553e-11 \n",
      "\n",
      "When l = 11, j_l = 3.099552e-12 \n",
      "\n",
      "When l = 12, j_l = 1.241663e-13 \n",
      "\n",
      "When l = 13, j_l = 4.604638e-15 \n",
      "\n",
      "When l = 14, j_l = 1.589576e-16 \n",
      "\n",
      "When l = 15, j_l = 5.132686e-18 \n",
      "\n",
      "When l = 16, j_l = 1.556708e-19 \n",
      "\n",
      "When l = 17, j_l = 4.451178e-21 \n",
      "\n",
      "When l = 18, j_l = 1.203856e-22 \n",
      "\n",
      "When l = 19, j_l = 3.088742e-24 \n",
      "\n",
      "When l = 20, j_l = 7.537796e-26 \n",
      "\n",
      "When l = 21, j_l = 1.753883e-27 \n",
      "\n",
      "When l = 22, j_l = 3.899361e-29 \n",
      "\n",
      "When l = 23, j_l = 8.300119e-31 \n",
      "\n",
      "When l = 24, j_l = 1.694580e-32 \n",
      "\n",
      "When l = 25, j_l = 3.323936e-34 \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "For x = 10.0 we have the following set of bessel functions: \n",
      "\n",
      "When l = 0, j_l = -5.440211e-02 \n",
      "\n",
      "When l = 1, j_l = 7.846694e-02 \n",
      "\n",
      "When l = 2, j_l = 7.794219e-02 \n",
      "\n",
      "When l = 3, j_l = -3.949584e-02 \n",
      "\n",
      "When l = 4, j_l = -1.055893e-01 \n",
      "\n",
      "When l = 5, j_l = -5.553451e-02 \n",
      "\n",
      "When l = 6, j_l = 4.450132e-02 \n",
      "\n",
      "When l = 7, j_l = 1.133862e-01 \n",
      "\n",
      "When l = 8, j_l = 1.255780e-01 \n",
      "\n",
      "When l = 9, j_l = 1.000964e-01 \n",
      "\n",
      "When l = 10, j_l = 6.460515e-02 \n",
      "\n",
      "When l = 11, j_l = 3.557441e-02 \n",
      "\n",
      "When l = 12, j_l = 1.721600e-02 \n",
      "\n",
      "When l = 13, j_l = 7.465584e-03 \n",
      "\n",
      "When l = 14, j_l = 2.941078e-03 \n",
      "\n",
      "When l = 15, j_l = 1.063543e-03 \n",
      "\n",
      "When l = 16, j_l = 3.559041e-04 \n",
      "\n",
      "When l = 17, j_l = 1.109407e-04 \n",
      "\n",
      "When l = 18, j_l = 3.238847e-05 \n",
      "\n",
      "When l = 19, j_l = 8.896627e-06 \n",
      "\n",
      "When l = 20, j_l = 2.308372e-06 \n",
      "\n",
      "When l = 21, j_l = 5.676978e-07 \n",
      "\n",
      "When l = 22, j_l = 1.327285e-07 \n",
      "\n",
      "When l = 23, j_l = 2.958029e-08 \n",
      "\n",
      "When l = 24, j_l = 6.298905e-09 \n",
      "\n",
      "When l = 25, j_l = 1.284342e-09 \n",
      "\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #import library\n",
    "\n",
    "X=[0.1, 1, 10] #create array containing the three values of x that we will want to calculate the \n",
    "\n",
    "#itterate for i = 0, 1, and 2\n",
    "for i in range (0, 3):\n",
    "    x=X[i] #sets the value of x to be the 0.1, 1 or 10 depending on the value of the index i\n",
    "    \n",
    "    bessel_array = [1.0, 1.0] #fills the bessel array with the initial values of j_51(x) = 1 and j_50(x) = 1. Note that these are not analytically correct initial conditions though our results will be largley indpendent of this fact).\n",
    "    \n",
    "    #calculate the value of j_l(x) using the recursion relation above and inserst j_l(x) into an array in such a way that at the end of the for loop, the lth element of the vector is j_l(x)\n",
    "    for l in range (50, 0, -1):\n",
    "        bessel_array.insert(0, ((2 * l + 1) / x) * bessel_array[0] - bessel_array[1])\n",
    "    \n",
    "    j_0_anal = sin(x) / x #creates a variable to store the true analytic value of j_0(x)\n",
    "    ratio = j_0_anal / bessel_array[0] #finds ratio between the analytic value of j_0(x) and our calculated value of j_0(x)\n",
    "    \n",
    "    bessel_array = np.asarray(bessel_array) #convert array to vector\n",
    "    \n",
    "    bessel_array = ratio * bessel_array     #uses the ratio between the analytic value of j_0(x) and our calculated value of j_0(x) as a corrective factor for the values of j_l(x) in the vector.\n",
    "    \n",
    "    #print the values for the spherical Bessel functions j_l(x) for x = 0.1, x = 1, and x = 10 and for l = 0, 1, ..., 25\n",
    "    print('For x = %.1f we have the following set of bessel functions: \\n' % (x))\n",
    "    for j in range (0, 26):\n",
    "        print('When l = %d, j_l = %e \\n' % (j, bessel_array[j]))\n",
    "    print('\\n \\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
