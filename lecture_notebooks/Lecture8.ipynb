{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Lecture 8*\n",
    "\n",
    "# Matrix Algebra and Fits to Data\n",
    "\n",
    "| |\n",
    "|:---:|\n",
    "|Selected Content [From **COMPUTATIONAL PHYSICS**, 3rd Ed, 2015](http://physics.oregonstate.edu/~rubin/Books/CPbook/index.html) <br>RH Landau, MJ Paez, and CC Bordeianu (deceased) <br>Copyrights: <br> [Wiley-VCH, Berlin;](http://www.wiley-vch.de/publish/en/books/ISBN3-527-41315-4/) and [Wiley & Sons, New York](http://www.wiley.com/WileyCDA/WileyTitle/productCd-3527413154.html)<br>  R Landau, Oregon State Unv, <br>MJ Paez, Univ Antioquia,<br> C Bordeianu, Univ Bucharest, 2015.<br> Support by National Science Foundation.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systems of Linear Equations as Matrix Equations\n",
    "\n",
    "Systems of linear equations occur all the time in physics.\n",
    "One example is the system of equations stemming from Kirchhoff's Law in a resistor circuit.\n",
    "\n",
    "<img src=\"Figures/Resistor_Network.png\" width=\"30%\">\n",
    "\n",
    "In this circuit, Kirchhoff's node and loop laws give a system of 3 equations:\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "I_1 + I_2 + I_3 \\\\\n",
    "-2 I_1 + 3 I_2 \\\\\n",
    "-3 I_2 + 6 I_3\n",
    "\\end{array}\n",
    "\\right)\n",
    "= \n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "0 \\\\\n",
    "24 \\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Such a system can be written in matrix form $\\bf{Ax} = \\bf{B}$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & 1 \\\\\n",
    "    -2 & 3 & 0 \\\\\n",
    "    0 & -3 & 6\n",
    "\\end{bmatrix}\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "I_1 \\\\\n",
    "I_2 \\\\\n",
    "I_3\n",
    "\\end{array}\n",
    "\\right]\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "24 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A small system of equations like this is relatively straightforward to solve manually:\n",
    "1. Use first line to solve for $I_1$ in terms of $I_2$ and $I_3$.\n",
    "2. Substitute this forward (*forward substitution*) into the second line, thereby eliminating $I_1$ in the second equation.\n",
    "3. Repeat, solving for $I_2$ in terms of $I_3$ and eliminating $I_2$.\n",
    "4. Solve for $I_3$ and use *backward substitution* in expressions for $I_2$ and subsequently $I_1$.\n",
    "\n",
    "This is essentially the **Gaussian elimination** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra in Python\n",
    "\n",
    "As seen in the text, the best way to handle matrices in Python is to create them as NumPy arrays.\n",
    "The NumPy package converts Python lists to proper arrays with the `array` function.\n",
    "The NumPy `linalg` package contains all of the linear algebra operations.\n",
    "\n",
    "List of NumPy operators and their effects.\n",
    "\n",
    "|*Operator* | *Effect*|*Operator*|*Effect*| \n",
    "|- - -|- - - |- - -|- - - | \n",
    "|dot(a,b\\[,out\\]) | Dot product arrays | vdot(a, b) | Dot product | \n",
    "|inner(a, b) | Inner product arrays |outer(a, b) | Outer product | \n",
    "|tensordot(a, b) | Tensor dot product | einsum( ) |Einstein sum | \n",
    "|linalg.matrix_power(M, n) | Matrix to power n | kron(a, b) | Kronecker product| \n",
    "|linalg.cholesky(a) | Cholesky decomp |linalg.qr(a)| QR factorization | \n",
    "|linalg.svd(a ) | Singular val decomp |linalg.eig(a) | Eigenproblem | \n",
    "|linalg.eigh(a) | Hermitian eigen |linalg.eigvals(a)| General eigen |\n",
    "|linalg.eigvalsh(a) | Hermitian eigenvals |linalg.norm(x) |Matrix norm | \n",
    "|linalg.cond(x) | Condition number |linalg.det(a) | Determinant | \n",
    "|linalg.slogdet(a) | Sign & log(det) |trace(a) | Diagnol sum | \n",
    "|linalg.solve(a, b) | Solve equation |linalg.tensorsolve(a, b) | Solve a x = b | \n",
    "|linalg.lstsq(a, b) |Least-squares solve |linalg.inv(a) | Inverse | \n",
    "|linalg.pinv(a) | Penrose inverse|linalg.tensorinv(a)| Inverse N-D array |\n",
    "\n",
    "Other languages, like C++, have similar libraries (`# include <matrix.h>`), all based on the standard [LAPACK libraries](http://www.netlib.org/lapack/).  (The no-nonsense web page lets you know that they are serious people.)\n",
    "\n",
    "For our small 3x3 matrix, the Python implementation and solution for $\\bf x$ looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. -2.  3.  0.  0. -3.  6.]\n",
      "[1, 2, 3]\n",
      "[1 2 3]\n",
      "[[ 1.  1.  1.]\n",
      " [-2.  3.  0.]\n",
      " [ 0. -3.  6.]]\n",
      "[[ 1. -2.  0.]\n",
      " [ 1.  3. -3.]\n",
      " [ 1.  0.  6.]]\n",
      "36.0\n",
      "[[ 0.]\n",
      " [24.]\n",
      " [ 0.]]\n",
      "x = [[-6.]\n",
      " [ 4.]\n",
      " [ 2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array([1., 1., 1., -2., 3., 0., 0., -3., 6.])\n",
    "print(inputs)\n",
    "mylist = [1,2,3]\n",
    "print(mylist)\n",
    "inputs2 = np.array([1,2,3])\n",
    "print(inputs2)\n",
    "A = inputs.reshape(3,3)\n",
    "print(A)\n",
    "print(A.T)\n",
    "print(np.linalg.det(A))\n",
    "\n",
    "inputs = np.array([0., 24., 0])\n",
    "b = inputs.reshape(3,1)\n",
    "print(b)\n",
    "\n",
    "x = np.linalg.solve(A,b)\n",
    "print(\"x =\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the currents: $I_1 = -6$, $I_2 = 4$, and $I_3 = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Elimination\n",
    "\n",
    "This method is applied \"behind the scenes\" of the NumPy `linalg` solver, but it is good to know the algorithm, nonetheless.\n",
    "\n",
    "The basic operations of Gaussian elimination (Gauss-Jordan method) are:\n",
    "1. Multiply a particular row in $\\bf A$ by a constant\n",
    "2. Add a multiple of one row to another\n",
    "3. Interchange two rows\n",
    "\n",
    "Each one of these can be expressed as a matrix operation:\n",
    "1. Multiply:\n",
    "$$\\begin{bmatrix}\n",
    "    1 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 \\\\\n",
    "    0 & 0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "2. Add a multiple:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 \\\\\n",
    "    -1/2 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "3. Interchange:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0 & 1 & 0 \\\\\n",
    "    1 & 0 & 0 \\\\\n",
    "    0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "These operations continue until we arrive at a **upper triangular matrix** of the form.\n",
    "The *forward substitution* phase is then complete.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    a & b & c \\\\\n",
    "    0 & d & e \\\\\n",
    "    0 & 0 & f\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    b_1  \\\\\n",
    "    b_2 \\\\\n",
    "    b_3 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then we solve for $x_3 = b_3/f$ and use that value to solve for $x_2$ in the second equation (second row).  \n",
    "This is called *back substitution*.\n",
    "The back substitution continues until we solve for $x_1$.\n",
    "\n",
    "Let's try to formalize and generalize the Gaussian elimination in terms of the matrix operations.\n",
    "\n",
    "For a starting matrix equation $\\bf{Ax} = \\bf{b}$, we write the matrix elements as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    a_{11} & a_{12} & a_{13} & \\cdots & a_{1N} \\\\\n",
    "    a_{21} & a_{22} & a_{23} & \\cdots & a_{2N} \\\\\n",
    "    a_{31} & a_{32} & a_{33} & \\cdots & a_{3N} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    a_{N1} & a_{N2} & a_{N3} & \\cdots & a_{NN}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    \\vdots \\\\\n",
    "    x_N\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    b_1  \\\\\n",
    "    b_2 \\\\\n",
    "    b_3 \\\\\n",
    "    \\vdots \\\\\n",
    "    b_N\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then, to eliminate $x_1$ in the second line, we multiply by a matrix $\\bf{M}_1$, with\n",
    "\n",
    "$$\n",
    "\\bf{M}_1 = \n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    -a_{21}/a_{11} & 1 & 0 & \\cdots & 0 \\\\\n",
    "    -a_{31}/a_{11} & 0 & 1 & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    -a_{N1}/a_{11} & 0 & 0 & \\cdots & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "After that single operation,\n",
    "\n",
    "$$\n",
    "{\\bf M}_1 {\\bf A} = \n",
    "\\begin{bmatrix}\n",
    "    a_{11} & a_{12} & a_{13} & \\cdots & a_{1N} \\\\\n",
    "    0 & a_{22}-\\frac{a_{21}}{a_{11}}a_{12} & a_{23}-\\frac{a_{21}}{a_{11}}a_{13} & \\cdots & a_{2N}-\\frac{a_{21}}{a_{11}}a_{1N} \\\\\n",
    "    0 & a_{32}-\\frac{a_{31}}{a_{11}}a_{12} & a_{33}-\\frac{a_{31}}{a_{11}}a_{13} & \\cdots & a_{3N}-\\frac{a_{31}}{a_{11}}a_{1N}\\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & a_{N2}-\\frac{a_{N1}}{a_{11}}a_{12} & a_{N3}-\\frac{a_{N1}}{a_{11}}a_{13} & \\cdots & a_{NN}-\\frac{a_{N1}}{a_{11}}a_{1N} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And, at the same time,\n",
    "\n",
    "$$\n",
    "{\\bf M}_1 {\\bf b}=\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 - \\frac{a_{21}}{a_{11}} b_1 \\\\\n",
    "b_3 - \\frac{a_{31}}{a_{11}} b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_N - \\frac{a_{N1}}{a_{11}} b_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Because we have performed the same operation on both sides of the equation, the new form and the original form are equivalent.\n",
    "In other words, a solution to this new equation is the same as the solution for the original equation.\n",
    "\n",
    "After a series of matrix operations $\\bf{M}_3 \\bf{M}_2 \\bf{M}_1 \\bf{A}$ (one for each variable), we will have an upper triangular  matrix for $\\bf A$.\n",
    "The process of backward substitution can be thought of in two different ways:\n",
    "1. Working $i=N-1, N-2, \\cdots, 1$, solve for $x_i$ with the formula\n",
    "$$x_i = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=i+1}^N a_{ij} x_j \\right)$$\n",
    "2. Matrix manipulations on both $\\bf A$ and $\\bf b$ so that the final system looks like \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    a_{11} & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & a_{22} & 0 & \\cdots & 0 \\\\\n",
    "    0 & 0 & a_{33} & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & 0 & \\cdots & a_{NN}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    \\vdots \\\\\n",
    "    x_N\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    b_1  \\\\\n",
    "    b_2 \\\\\n",
    "    b_3 \\\\\n",
    "    \\vdots \\\\\n",
    "    b_N\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "From this form, the $a_{ij}$ coefficients can even be absorbed into the $\\bf b$ vector:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "    0 & 1 & 0 & \\cdots & 0 \\\\\n",
    "    0 & 0 & 1 & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & 0 & \\cdots & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    \\vdots \\\\\n",
    "    x_N\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    b_1 / a_{11}  \\\\\n",
    "    b_2 / a_{22} \\\\\n",
    "    b_3 / a_{33} \\\\\n",
    "    \\vdots \\\\\n",
    "    b_N / a_{NN}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From this form, the solutions $x_i$ can be read off directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting in Gaussian Elimination\n",
    "\n",
    "The \"pivot\" in Gaussian elimination is swinging the entire matrix around one line in order to remove elements below its diagonal element.\n",
    "\n",
    "For example, the first operation in Gaussian elimination is intended to produce $a_{11}=1$, and the second operation makes $a_{21}=0$.\n",
    "\n",
    "Since this second operation depends on the factor $-a_{21}/a_{11}$, we run into trouble if a diagonal element is 0, or so close to 0 as to cause numerical instability.  \n",
    "In that case, it would be better to eliminate a different variable first, perhaps by exchanging rows.\n",
    "\n",
    "For example, consider the system\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0 & 1 \\\\\n",
    "    1 & 1 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    1  \\\\\n",
    "    2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In this case, $a_{11}=0$, so the first step of elimination ($a_{21}/a_{11}$) can't be completed.\n",
    "\n",
    "If we switch rows 1 and 2 like this:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    0 & 1 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    2  \\\\\n",
    "    1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then the forward elimination is all done, and we can proceed immediately to the backward substitution.\n",
    "(Notice that the $\\bf x$ vector does not change.)\n",
    "\n",
    "But there is another wrinkle here.\n",
    "If $a_{11}$ is not exactly 0 but merely small *compared to the other coefficients in the row*, then the sums suffer from limited precision.\n",
    "In our simple 3x3 matrix, when\n",
    "$b_2 - \\frac{a_{21}}{a_{11}} b_1 \\approx\n",
    "b_3 - \\frac{a_{31}}{a_{11}} b_1$, and the resulting $x$ values will be wrong.\n",
    "\n",
    "The fix for this problem is to exchange rows so that the row with the largest $a_{1j}$ value (relative to the max weight in the row) lands with that value on the diagonal.  \n",
    "(It is effectively moved to the top of the matrix, although it may actually be left in place to avoid moving around elements in memory.)\n",
    "\n",
    "Even if there are no zeros on the diagonal, this procedure still makes best use of the limited machine precision.\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    3 & -13 & 9 & 3 \\\\\n",
    "    -6 & 4 & 1 & -18 \\\\\n",
    "    6 & -2 & 2 & 4 \\\\\n",
    "    12 & -8 & 6 & 10\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    x_4\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    -19  \\\\\n",
    "    -34 \\\\\n",
    "    16 \\\\\n",
    "    26\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The largest value of $a_{1j}$ *relative to the maximum value in the row* is 6 at $j=3$.  It's the same (100%) at $j=4$, but we give the tie to the first instance.\n",
    "Therefore, we eliminate all of the coefficients $a_{1j}$ except $a_{13}$:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0 & -12 & 8 & 1 \\\\\n",
    "    0 & 2 & 3 & -14 \\\\\n",
    "    6 & -2 & 2 & 4 \\\\\n",
    "    0 & -4 & 2 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    x_4\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    -27 \\\\\n",
    "    -18 \\\\\n",
    "    16 \\\\\n",
    "    -6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "After 2 more repeats of this procedure, we would have an upper diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LU Factorization\n",
    "\n",
    "It turns out that the simple Gaussian elimination we pursued actually factorizes $\\bf A$ into two matrices: a *lower unit triangular* matrix $\\bf L$ and an *upper triangular* matrix $\\bf U$.\n",
    "\n",
    "$$ {\\bf L} = \n",
    "\\begin{bmatrix}\n",
    "    1 &  &  &  &  \\\\\n",
    "    \\ell_{21} & 1 &  &  &  \\\\\n",
    "    \\ell_{31} & \\ell_{32} & 1 &  &  \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\ell_{N1} & \\ell_{N2} & \\ell_{N3} & \\cdots & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ {\\bf U} =\n",
    "\\begin{bmatrix}\n",
    "    u_{11} & u_{12} & u_{13} & \\cdots & u_{1N} \\\\\n",
    "     & u_{22} & u_{23} & \\cdots & u_{2N} \\\\\n",
    "     &  & u_{33} & \\cdots & u_{3N} \\\\\n",
    "     &  &  & \\ddots & \\vdots \\\\\n",
    "     &  &  &  & u_{NN}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is the **LU factorization** of $\\bf A$:\n",
    "$${\\bf A} = {\\bf L}{\\bf U}$$\n",
    "\n",
    "We know that our Gaussian elimination transformed the left-hand side of the equation into an upper triangular matrix during forward elimination, but where does the lower triangular matrix come from?\n",
    "\n",
    "Hint: that forward elimination created an equivalent equation\n",
    "$$ {\\bf MAx} = {\\bf Mb}$$\n",
    "\n",
    "Start again with the example 4x4 matrix:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    6 & -2 & 2 & 4 \\\\\n",
    "    12 & -8 & 6 & 10 \\\\\n",
    "    3 & -13 & 9 & 3 \\\\\n",
    "    -6 & 4 & 1 & -18 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    x_4\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    16 \\\\\n",
    "    26 \\\\\n",
    "    -19  \\\\\n",
    "    -34 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "After the forward elimination, we would find\n",
    "\n",
    "$$ {\\bf M A} = {\\bf M}_3 {\\bf M}_2 {\\bf M}_1 {\\bf A} = \n",
    "\\begin{bmatrix}\n",
    "    6 & -2 & 2 & 4 \\\\\n",
    "    0 & -4 & 2 & 2 \\\\\n",
    "    0 & 0 & 2 & -5 \\\\\n",
    "    0 & 0 & 0 & -3 \\\\\n",
    "\\end{bmatrix}\n",
    "= {\\bf U}\n",
    "$$\n",
    "\n",
    "But what are the forms of the ${\\bf M}_1$, etc.?\n",
    "They are supposed to multiply the relevant coefficient by a negative multiplier so that it can be summed and wiped out.\n",
    "\n",
    "${\\bf M}_1$ is the first step in the Gaussian elimination:\n",
    "\n",
    "$$ {\\bf M}_1= \n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    -2 & 1 & 0 & 0 \\\\\n",
    "    -\\frac{1}{2} & 0 & 1 & 0 \\\\\n",
    "    1 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is a unit lower triangular matrix -- we are on the right track to understanding $\\bf L$.\n",
    "In fact, all of those operation matrices are unit lower triangular, since they operate on elements below the diagonal only.\n",
    "\n",
    "### Factorization\n",
    "\n",
    "Using linear algebra notation\n",
    "\n",
    "$$\\begin{align}\n",
    "{\\bf M A} &= {\\bf U} \\\\\n",
    "{\\bf M}^{-1} {\\bf M A} &= {\\bf M}^{-1} {\\bf U} \\\\\n",
    "{\\bf A} &= {\\bf M}^{-1} {\\bf U} \\\\\n",
    "& = {\\bf M}_1^{-1} {\\bf M}_2^{-1} {\\bf M}_3^{-1}{\\bf U} \\\\\n",
    "{\\bf A} &= {\\bf L U}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "But how do we figure out ${\\bf M}_1^{-1}$?\n",
    "It is as easy as taking the negative of the elimination multipliers below the diagonal!\n",
    "\n",
    "$$ {\\bf M}_1^{-1}= \n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    2 & 1 & 0 & 0 \\\\\n",
    "    \\frac{1}{2} & 0 & 1 & 0 \\\\\n",
    "    -1 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   0.   0.   0. ]\n",
      " [-2.   1.   0.   0. ]\n",
      " [-0.5  0.   1.   0. ]\n",
      " [ 1.   0.   0.   1. ]]\n",
      "[[ 1.  -0.  -0.  -0. ]\n",
      " [ 2.   1.   0.   0. ]\n",
      " [ 0.5  0.   1.   0. ]\n",
      " [-1.   0.   0.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1., 0., 0., 0., -2., 1., 0., 0., \n",
    "                -0.5, 0., 1., 0., 1., 0., 0., 1.])\n",
    "M1 = inputs.reshape(4,4)\n",
    "print(M1)\n",
    "print(np.linalg.inv(M1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can multiply together the ${\\bf M}_n^{-1}$ matrices to get $\\bf L$ (see below).\n",
    "\n",
    "In summary,\n",
    "* ${\\bf A} = {\\bf L U}$\n",
    "* ${\\bf L}$ is the matrix of (negative) elimination multipliers that are applied to the original ${\\bf A}$ to arrive at ${\\bf U}$.  In other words, ${\\bf L}^{-1} {\\bf A} = {\\bf U}$.\n",
    "* ${\\bf U}$ is the final matrix of coefficients after the forward elimination phase is complete\n",
    "\n",
    "The original problem was to solve \n",
    "\n",
    "$$\\begin{align}\n",
    "{\\bf A x} &= {\\bf b} \\\\\n",
    "{\\bf L U x} &= {\\bf b} \\\\\n",
    "{\\bf L} ({\\bf U x}) &= {\\bf b}\n",
    "\\end{align}$$\n",
    "\n",
    "We have simplified this to two triangular systems:\n",
    "* ${\\bf L z} = {\\bf b}$ (forward elimination)\n",
    "* ${\\bf U x} = {\\bf z}$ (back substitution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.  -2.   2.   4.]\n",
      " [ 12.  -8.   6.  10.]\n",
      " [  3. -13.   9.   3.]\n",
      " [ -6.   4.   1. -18.]]\n",
      "[[ 1.          0.          0.          0.        ]\n",
      " [ 0.25        1.          0.          0.        ]\n",
      " [-0.5        -0.          1.          0.        ]\n",
      " [ 0.5        -0.18181818  0.09090909  1.        ]]\n",
      "[[ 12.          -8.           6.          10.        ]\n",
      " [  0.         -11.           7.5          0.5       ]\n",
      " [  0.           0.           4.         -13.        ]\n",
      " [  0.           0.           0.           0.27272727]]\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "inputs = np.array([6.,-2.,2.,4.,12.,-8.,6.,10.,\n",
    "                3.,-13.,9.,3.,-6.,4.,1.,-18.])\n",
    "A = inputs.reshape(4,4)\n",
    "print(A)\n",
    "\n",
    "(p,L,U) = scipy.linalg.lu(A)\n",
    "print(L)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Fitting\n",
    "\n",
    "We will assume the chi-square ($\\chi^2$) measure of how well a theoretical function $g$\n",
    "reproduces data.\n",
    "This measure comes from the maximum likelihood method.\n",
    "\n",
    "$$\n",
    " \\chi^{2}  =  \\sum_{i=1}^{N_{D}}\n",
    "\\left(\\frac{y_{i} - g(x_{i}, a_m)} {\\sigma_{i}}\\right)^{2}$$\n",
    "\n",
    "Note that this form includes uncertainties on the measured points, unlike the interpolation forms (cubic splines, etc.) that we discussed last time.\n",
    "\n",
    "*Least-squares fitting* refers to adjusting the internal parameters $a_m$ in the theory\n",
    "until a minimum in $\\chi^2$ is found, that is, finding a curve\n",
    "that produces the least value for the summed squares of the deviations\n",
    "of the data from the function $g(x)$. In general, this is the best fit\n",
    "possible and the best way to determine the parameters in a theory.\n",
    "\n",
    "In general, the dependence of $g$ on the internal parameters of the theory) is not necessarily linear.\n",
    "It is still possible to find parameter values that minimize the $\\chi^2$ by using a trial-and-error method (bisection method) in a multi-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fits of Linear Functions\n",
    "\n",
    "If the function being fitted does depend only\n",
    "*linearly* on the unknown parameters $a_m$, then the condition of\n",
    "minimum $\\chi^2$ leads to a set of simultaneous linear equations\n",
    "for the $a_m$ that can be solved using numerical matrix\n",
    "techniques.\n",
    "\n",
    "For example, if we want to fit $$g(x) = a_1 + a_2x + a_3x^{2}$$\n",
    "to some experimental measurements\n",
    "we can still make a linear fit although $x$ is raised\n",
    "to the second power.  The dependence on the $a_m$ parameters must be linear; that's all.\n",
    "\n",
    "The $\\chi^2$ minimization leads to the\n",
    "three simultaneous equations for the three $a_m$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\sum_{i=1}^{N_{D}}  \\frac{[y_{i}-g(x_{i})]}{\\sigma_{i}^{2}}\n",
    "\\frac{\\partial g(x_i)} {\\partial a_{1}} & =  0, \\quad\n",
    "\\frac{\\partial g}{\\partial a_1} =1,\\\\\n",
    "\\sum_{i=1}^{N_{D}}  \\frac{[y_{i}-g(x_{i})]}{\\sigma_{i}^{2}}\n",
    "\\frac{\\partial g(x_i)} {\\partial a_{2}} & =  0, \\quad \\frac{\\partial g}{\\partial a_2} =\n",
    "x,\\\\\n",
    "\\sum_{i=1}^{N_{D}}   \\frac{[y_{i}-g(x_{i})]}{\\sigma_{i}^{2}}\n",
    " \\frac{\\partial g(x_i)} {\\partial a_{3}} & =  0 , \\quad \\frac{\\partial g}{\\partial\n",
    " a_3}=x^2\n",
    "\\end{align}$$\n",
    " \n",
    "The key here is that all of these equations are linear in $x_1, x_2, \\dots, x_N$, so we can write the system of equations in matrix form.\n",
    "\n",
    "The system of equations:\n",
    "$$\\begin{align}\n",
    "S a_1 + S_{x}a_2 + S_{xx}a_3 & = S_{y}, \\\\ S_{x}a_1 + S_{xx} a_2 + S_{xxx} a_3 & =\n",
    "S_{xy}, \\\\ S_{xx} a_1 + S_{xxx} a_2 + S_{xxxx} a_3 & = S_{xxy} \\end{align}$$\n",
    "\n",
    "can be converted to matrix form with unknown parameter values (collected in unknown vector $\\bf x$):\n",
    "\n",
    "$$\\begin{align}\n",
    " &{\\bf A}{\\bf x}  = {\\bf b},  \\\\\n",
    " &{\\bf A}  = \\left[\\begin{array}{lll}\n",
    "S & S_{x} & S_{xx}\\\\\n",
    " S_{x} & S_{xx} & S_{xxx} \\\\\n",
    " S_{xx} & S_{xxx} & S_{xxxx}\\end{array} \\right]\\!,\\quad\n",
    " {\\bf x} =\n",
    "\\left[\\begin{array}{l}\n",
    "a_1\\\\ a_2\\\\ a_3\\end{array} \\right]\\!,\\quad {\\bf b} =\n",
    "\\left[\\begin{array}{l} S_{y}\\\\ S_{xy}\\\\ S_{xxy}\n",
    "\\end{array} \\right]\n",
    "\\end{align}$$\n",
    "\n",
    "Then the solution for $\\bf x$ depends on solving the equation using numerical methods.\n",
    "Once we have the parameter values $a_m$, we have the complete function of the fitted curve \n",
    "$$g(x) = a_1 + a_2x + a_3x^{2}$$ for any set of $x$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " x vector via inverse\n",
      "[[ 1002.06558106 -2280.45983096  1269.8244017 ]\n",
      " [-1432.41585118  3291.93302443 -1847.84729682]\n",
      " [  483.14350806 -1119.31382351   633.40751278]] \n",
      "\n",
      "A*inverse(A)\n",
      "[[  518.00849046 -1018.54883857   501.54034811]\n",
      " [-1018.54883857  2146.48279098 -1126.93395241]\n",
      " [  501.54034811 -1126.93395241   626.3936043 ]] \n",
      "\n",
      "x Matrix via direct\n",
      "[-8.5698482  11.66987644 -2.76280268] end= \n",
      "FitParabola Final Results\n",
      "\n",
      "y(x) = a0 + a1 x + a2 x^2\n",
      "a0 =  1.0\n",
      "a1 =  1.1\n",
      "a2 =  1.24 \n",
      "\n",
      " i   xi     yi    yfit   \n",
      " 0 1.000  0.520  0.3372256 \n",
      "\n",
      " 1 1.100  0.800  0.9240246 \n",
      "\n",
      " 2 1.240  0.700  1.6527132 \n",
      "\n",
      " 3 1.350  1.800  2.1492771 \n",
      "\n",
      " 4 1.451  2.900  2.5463350 \n",
      "\n",
      " 5 1.500  2.900  2.7186604 \n",
      "\n",
      " 6 1.920  3.600  3.6515188 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" From \"COMPUTATIONAL PHYSICS\", 3rd Ed \n",
    "    by RH Landau, MJ Paez, and CC Bordeianu\n",
    "    Copyright Wiley-VCH Verlag GmbH & Co. KGaA, Berlin;  Copyright R Landau,\n",
    "    Oregon State Unv, MJ Paez, Univ Antioquia, C Bordeianu, Univ Bucharest, 2015.\n",
    "    Support by National Science Foundation\"\"\"\n",
    "\n",
    "# Fit.py     Linear least square fit; e.g. of matrix computation arrays\n",
    "\t \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import solve\n",
    "\n",
    "t = np.arange(1.0, 2.0, 0.1)                             # x range curve\n",
    "x = np.array([1., 1.1, 1.24, 1.35,  1.451, 1.5, 1.92])   # Given x values\n",
    "y = np.array([0.52, 0.8, 0.7, 1.8, 2.9, 2.9, 3.6])       # Given y values\n",
    "plt.plot(x, y, 'bo' )                                    # Plot data in blue\n",
    "sig = np.array([0.1, 0.1, 0.2, 0.3, 0.2, 0.1, 0.1])      # error bar lenghts\n",
    "plt.errorbar(x,y,sig)                                    # Plot error bars\n",
    "plt.title('Linear Least Square Fit')                     # Plot figure\n",
    "plt.xlabel( 'x' )                                        # Label axes\n",
    "plt.ylabel( 'y' )\n",
    "plt.grid(True)                                           # plot grid\n",
    "Nd = 7\n",
    "A = np.zeros( (3,3), float )                                # Initialize\n",
    "bvec = np.zeros( (3,1), float )\n",
    "ss = sx = sxx = sy = sxxx = sxxxx = sxy = sxy = sxxy = 0.\n",
    "\n",
    "for i in range(0, Nd):                                      \n",
    "        sig2 = sig[i] * sig[i]\n",
    "        ss  += 1. / sig2;    sx   += x[i]/sig2;        sy    += y[i]/sig2\n",
    "        rhl  = x[i] * x[i];  sxx  += rhl/sig2;   sxxy  += rhl * y[i]/sig2\n",
    "        sxy += x[i]*y[i]/sig2; sxxx +=rhl*x[i]/sig2; sxxxx +=rhl*rhl/sig2\n",
    "       \n",
    "A    = np.array([ [ss,sx,sxx], [sx,sxx,sxxx], [sxx,sxxx,sxxxx] ])\n",
    "bvec = np.array([sy, sxy, sxxy])\n",
    "\n",
    "xvec = np.multiply(inv(A), bvec)                             # Invert matrix\n",
    "Itest = np.multiply(A, inv(A))                             # Matrix multiply\n",
    "print('\\n x vector via inverse')                                       \n",
    "print(xvec, '\\n')\n",
    "print('A*inverse(A)')\n",
    "print(Itest, '\\n')\n",
    "\n",
    "xvec = solve(A, bvec)                             # Solve via elimination\n",
    "print('x Matrix via direct') \n",
    "print(xvec, 'end= ') \n",
    "print('FitParabola Final Results\\n') \n",
    "print('y(x) = a0 + a1 x + a2 x^2')                          # Desired fit\n",
    "print('a0 = ', x[0])                  \n",
    "print('a1 = ', x[1])\n",
    "print('a2 = ', x[2], '\\n')\n",
    "print(' i   xi     yi    yfit   ')\n",
    "for i in range(0, Nd):\n",
    "    s = xvec[0] + xvec[1]*x[i] + xvec[2]*x[i]*x[i]\n",
    "    print(\" %d %5.3f  %5.3f  %8.7f \\n\"  %(i, x[i], y[i], s))\n",
    "# red line is the fit, red dots the fits at y[i]\n",
    "curve  = xvec[0] + xvec[1]*t + xvec[2]*t**2\n",
    "points = xvec[0] + xvec[1]*x + xvec[2]*x**2\n",
    "plt.plot(t, curve,'r', x, points, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fits of Nonlinear Functions Using Linear Approximations\n",
    "\n",
    "If the theoretical function $g(x, a_m)$ is not a linear function of the parameters $a_m$, then the equations that\n",
    "result from minimizing $\\chi^2$ are not linear equations and so\n",
    "cannot be solved by the techniques of *linear* algebra (matrix methods).\n",
    "\n",
    "There are two possibilities for trying to recast these non-linear equations into linear approximations:\n",
    "* Modify the equations in the form of an expansion about some local (unknown) minimum value\n",
    "* Use the Newton-Raphson method (internal linear approximation) to solve for the roots of the homogeneous non-linear equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
